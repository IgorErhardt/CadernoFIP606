[
  {
    "objectID": "IntroR.html",
    "href": "IntroR.html",
    "title": "Caderno FIP606",
    "section": "",
    "text": "Operadores de atribuição: &lt;- é o mais usado, embora = funcione.\n\nx &lt;- 10        # atribui 10 a x\ny = 5          # atribui 5 a y\n\nNomes de variáveis: usam letras, números, . e _, mas não podem começar com número ou ponto seguido de número. Exemplo:\n\npontuacao_aluno &lt;- 90\n.variavel_oculta &lt;- 1   # válido, mas desaconselhado\n\n\n\n\n\n\nCriar vetores: c(), : e seq().\n\nnums &lt;- c(1, 2, 3, 4)\nseq_vezes &lt;- seq(from=0, to=1, length.out=5)\nintervalo &lt;- 1:5\n\nOperações aritméticas:\n\na &lt;- c(1,2,3); b &lt;- c(4,5,6)\na + b   # c(5,7,9)\n\n[1] 5 7 9\n\na * 2   # c(2,4,6)\n\n[1] 2 4 6\n\n\nRegra de reciclagem: vetores menores se repetem para igualar o tamanho:\nc(1,2) + c(1,2,3,4)  # c(2,4,4,6)\n\n\n\n\n\nComparação: &lt;, &gt;, &lt;=, &gt;=, ==, !=.\nLógicos: & (E elemento a elemento), | (OU elemento a elemento), ! (NÃO). Use &&, || para condição única.\n\nx &lt;- c(1, 2, 3)\nx &gt; 1       # c(FALSE, TRUE, TRUE)\n\n[1] FALSE  TRUE  TRUE\n\nx &gt;= 2 & x &lt;= 3   # c(FALSE, TRUE, TRUE)\n\n[1] FALSE  TRUE  TRUE\n\n\n\n\n\n\n\nNA: falta de dado; NaN: resultado indefinido; Inf/-Inf: infinito.\nFunções: is.na(), is.nan(), is.finite(), is.infinite().\nTratamento de NAs:\n\ndados &lt;- c(1, NA, 3)\ndados &lt;- na.omit(dados)\nmean(dados, na.rm=TRUE)\n\n[1] 2"
  },
  {
    "objectID": "IntroR.html#atribuição-e-variáveis",
    "href": "IntroR.html#atribuição-e-variáveis",
    "title": "Caderno FIP606",
    "section": "",
    "text": "Operadores de atribuição: &lt;- é o mais usado, embora = funcione.\n\nx &lt;- 10        # atribui 10 a x\ny = 5          # atribui 5 a y\n\nNomes de variáveis: usam letras, números, . e _, mas não podem começar com número ou ponto seguido de número. Exemplo:\n\npontuacao_aluno &lt;- 90\n.variavel_oculta &lt;- 1   # válido, mas desaconselhado"
  },
  {
    "objectID": "IntroR.html#vetores-e-operações-elementares",
    "href": "IntroR.html#vetores-e-operações-elementares",
    "title": "Caderno FIP606",
    "section": "",
    "text": "Criar vetores: c(), : e seq().\n\nnums &lt;- c(1, 2, 3, 4)\nseq_vezes &lt;- seq(from=0, to=1, length.out=5)\nintervalo &lt;- 1:5\n\nOperações aritméticas:\n\na &lt;- c(1,2,3); b &lt;- c(4,5,6)\na + b   # c(5,7,9)\n\n[1] 5 7 9\n\na * 2   # c(2,4,6)\n\n[1] 2 4 6\n\n\nRegra de reciclagem: vetores menores se repetem para igualar o tamanho:\nc(1,2) + c(1,2,3,4)  # c(2,4,4,6)"
  },
  {
    "objectID": "IntroR.html#operadores-lógicos-e-de-comparação",
    "href": "IntroR.html#operadores-lógicos-e-de-comparação",
    "title": "Caderno FIP606",
    "section": "",
    "text": "Comparação: &lt;, &gt;, &lt;=, &gt;=, ==, !=.\nLógicos: & (E elemento a elemento), | (OU elemento a elemento), ! (NÃO). Use &&, || para condição única.\n\nx &lt;- c(1, 2, 3)\nx &gt; 1       # c(FALSE, TRUE, TRUE)\n\n[1] FALSE  TRUE  TRUE\n\nx &gt;= 2 & x &lt;= 3   # c(FALSE, TRUE, TRUE)\n\n[1] FALSE  TRUE  TRUE"
  },
  {
    "objectID": "IntroR.html#valores-ausentes-e-especiais",
    "href": "IntroR.html#valores-ausentes-e-especiais",
    "title": "Caderno FIP606",
    "section": "",
    "text": "NA: falta de dado; NaN: resultado indefinido; Inf/-Inf: infinito.\nFunções: is.na(), is.nan(), is.finite(), is.infinite().\nTratamento de NAs:\n\ndados &lt;- c(1, NA, 3)\ndados &lt;- na.omit(dados)\nmean(dados, na.rm=TRUE)\n\n[1] 2"
  },
  {
    "objectID": "IntroR.html#vetores-atômicos-e-coerção",
    "href": "IntroR.html#vetores-atômicos-e-coerção",
    "title": "Caderno FIP606",
    "section": "2.1 Vetores Atômicos e Coerção",
    "text": "2.1 Vetores Atômicos e Coerção\n\nTipos: numeric, integer, character, logical, complex, raw.\nHierarquia de coerção: logical -&gt; integer -&gt; numeric -&gt; complex -&gt; character.\n\nmisto &lt;- c(TRUE, 2, \"a\")  # convertido para character"
  },
  {
    "objectID": "IntroR.html#fatores",
    "href": "IntroR.html#fatores",
    "title": "Caderno FIP606",
    "section": "2.2 Fatores",
    "text": "2.2 Fatores\n\nDados categóricos com níveis fixos.\n\nf &lt;- factor(c(\"baixo\",\"médio\",\"alto\"), levels=c(\"baixo\",\"médio\",\"alto\"))\nlevels(f)\n\n[1] \"baixo\" \"médio\" \"alto\" \n\ntable(f)\n\nf\nbaixo médio  alto \n    1     1     1 \n\n\nConverter: as.character(f), as.numeric(f)."
  },
  {
    "objectID": "IntroR.html#datas-e-horários",
    "href": "IntroR.html#datas-e-horários",
    "title": "Caderno FIP606",
    "section": "2.3 Datas e Horários",
    "text": "2.3 Datas e Horários\n\nDate: as.Date(\"2025-07-09\"), formatos %Y-%m-%d.\nPOSIXct/POSIXlt: data-hora.\n\nd &lt;- as.Date(\"2025-07-09\", \"%Y-%m-%d\")\ndt &lt;- as.POSIXct(\"2025-07-09 15:00:00\")\n\nPacote lubridate:\n\nlibrary(lubridate)\nymd(\"20250709\")\n\n[1] \"2025-07-09\"\n\nmdy(\"07-09-2025\")\n\n[1] \"2025-07-09\"\n\nhms(\"15:00:00\")\n\n[1] \"15H 0M 0S\""
  },
  {
    "objectID": "IntroR.html#listas",
    "href": "IntroR.html#listas",
    "title": "Caderno FIP606",
    "section": "2.4 Listas",
    "text": "2.4 Listas\n\nColeções heterogêneas ordenadas.\nAcesso: [[ ]] ou $.\n\nlst &lt;- list(nome=\"Igor\", notas=c(90,95), aprovado=TRUE)\nlst[[\"notas\"]]\n\n[1] 90 95\n\nlst$aprovado\n\n[1] TRUE"
  },
  {
    "objectID": "IntroR.html#data-frames-e-tibbles",
    "href": "IntroR.html#data-frames-e-tibbles",
    "title": "Caderno FIP606",
    "section": "2.5 Data Frames e Tibbles",
    "text": "2.5 Data Frames e Tibbles\n\nTabelas bidimensionais heterogêneas.\n\ndf &lt;- data.frame(id=1:3, nota=c(10,20,15), stringsAsFactors=FALSE)\n\nTibbles:\n\nlibrary(tibble)\ntb &lt;- tibble(id=1:3, nota=c(10,20,15))\n\nInspeção: str(), head(), glimpse()."
  },
  {
    "objectID": "IntroR.html#matrizes-e-arrays",
    "href": "IntroR.html#matrizes-e-arrays",
    "title": "Caderno FIP606",
    "section": "2.6 Matrizes e Arrays",
    "text": "2.6 Matrizes e Arrays\n\nMatriz: bidimensional homogênea (matrix()).\nArray: estruturas com múltiplas dimensões (array()).\nAcesso: [linha, coluna] ou [i,j,k]."
  },
  {
    "objectID": "IntroR.html#leitura-de-dados",
    "href": "IntroR.html#leitura-de-dados",
    "title": "Caderno FIP606",
    "section": "3.1 Leitura de Dados",
    "text": "3.1 Leitura de Dados\n\nCSV: read.csv(), read_csv() (readr).\nExcel: readxl::read_excel().\nAlta performance: data.table::fread(), vroom::vroom()."
  },
  {
    "objectID": "IntroR.html#princípios-de-dados-tidy",
    "href": "IntroR.html#princípios-de-dados-tidy",
    "title": "Caderno FIP606",
    "section": "3.2 Princípios de Dados Tidy",
    "text": "3.2 Princípios de Dados Tidy\n\nCada variável em uma coluna, cada observação em uma linha.\ntidyr:\n\npivot_longer(), pivot_wider()\nseparate(), unite()"
  },
  {
    "objectID": "IntroR.html#workflow-dplyr",
    "href": "IntroR.html#workflow-dplyr",
    "title": "Caderno FIP606",
    "section": "3.3 Workflow dplyr",
    "text": "3.3 Workflow dplyr\n\nlibrary(dplyr)\ndf %&gt;%\n  filter(nota &gt; 10) %&gt;%\n  select(id, nota) %&gt;%\n  mutate(pct = nota / max(nota)) %&gt;%\n  arrange(desc(pct))\n\n  id nota  pct\n1  2   20 1.00\n2  3   15 0.75\n\n\n\nOperações agrupadas:\n\ndf %&gt;% group_by(id) %&gt;% summarise(nota_media = mean(nota))\n\n# A tibble: 3 × 2\n     id nota_media\n  &lt;int&gt;      &lt;dbl&gt;\n1     1         10\n2     2         20\n3     3         15"
  },
  {
    "objectID": "IntroR.html#conjuntos-de-dados-embutidos",
    "href": "IntroR.html#conjuntos-de-dados-embutidos",
    "title": "Caderno FIP606",
    "section": "3.4 Conjuntos de Dados Embutidos",
    "text": "3.4 Conjuntos de Dados Embutidos\nO R disponibiliza diversos conjuntos de dados (datasets) prontos para uso, úteis para exemplos e testes:\n\niris: medidas de sépalas e pétalas de três espécies de íris.\nmtcars: características de desempenho de diversos modelos de automóveis.\nairquality: medições diárias de qualidade do ar em Nova York.\n\nPara listar todos os datasets embutidos, use: data()\nPara carregar explicitamente um dataset:\n\ndata(iris)\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa"
  },
  {
    "objectID": "IntroR.html#componentes-básicos",
    "href": "IntroR.html#componentes-básicos",
    "title": "Caderno FIP606",
    "section": "4.1 Componentes Básicos",
    "text": "4.1 Componentes Básicos\n\nggplot(dados, aes(…)): define dados e mapeamentos.\nCamadas geom: geom_point(), geom_line(), geom_bar(), geom_histogram().\nFacetas: facet_wrap(), facet_grid()."
  },
  {
    "objectID": "IntroR.html#customização",
    "href": "IntroR.html#customização",
    "title": "Caderno FIP606",
    "section": "4.2 Customização",
    "text": "4.2 Customização\n\nTemas: theme_minimal(), theme_classic().\nRótulos: labs(title=, subtitle=, x=, y=, caption=).\nLegendas: theme(legend.position = \"bottom\")."
  },
  {
    "objectID": "IntroR.html#exemplos",
    "href": "IntroR.html#exemplos",
    "title": "Caderno FIP606",
    "section": "4.3 Exemplos",
    "text": "4.3 Exemplos\n\nlibrary(ggplot2)\nggplot(mtcars, aes(x=wt, y=mpg, color=factor(cyl))) +\n  geom_point(size=3) +\n  facet_wrap(~cyl) +\n  labs(\n    title = \"MPG vs Peso por Cilindro\",\n    x = \"Peso (1000 lbs)\",\n    y = \"Milhas por Galão\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Histograma com densidade\nggplot(iris, aes(x=Sepal.Length, fill=Species)) +\n  geom_histogram(alpha=0.6, position=\"identity\", bins=30) +\n  geom_density(alpha=0.4) +\n  labs(title=\"Distribuição do Comprimento da Sépala\")"
  },
  {
    "objectID": "IntroR.html#modelos-lineares-lm",
    "href": "IntroR.html#modelos-lineares-lm",
    "title": "Caderno FIP606",
    "section": "5.1 Modelos Lineares (lm)",
    "text": "5.1 Modelos Lineares (lm)\n\nmodelo &lt;- lm(nota ~ id + I(id^2), data=df)\nsummary(modelo)\n\n\nCall:\nlm(formula = nota ~ id + I(id^2), data = df)\n\nResiduals:\nALL 3 residuals are 0: no residual degrees of freedom!\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)    -15.0        NaN     NaN      NaN\nid              32.5        NaN     NaN      NaN\nI(id^2)         -7.5        NaN     NaN      NaN\n\nResidual standard error: NaN on 0 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:    NaN \nF-statistic:   NaN on 2 and 0 DF,  p-value: NA\n\n\n\nInterpretar coeficientes, p-valores, R² e resíduos.\nDiagnósticos: plot(modelo)."
  },
  {
    "objectID": "IntroR.html#modelos-lineares-generalizados-glm",
    "href": "IntroR.html#modelos-lineares-generalizados-glm",
    "title": "Caderno FIP606",
    "section": "5.2 Modelos Lineares Generalizados (glm)",
    "text": "5.2 Modelos Lineares Generalizados (glm)\n\ndf$aprovado &lt;- df$nota &gt;= 12\nglm_bin &lt;- glm(aprovado ~ nota, family = binomial(link = \"logit\"), data = df)\nsummary(glm_bin)\n\n\nCall:\nglm(formula = aprovado ~ nota, family = binomial(link = \"logit\"), \n    data = df)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)   -116.146 252537.088       0        1\nnota             9.269  18831.344       0        1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 3.8191e+00  on 2  degrees of freedom\nResidual deviance: 3.5965e-10  on 1  degrees of freedom\nAIC: 4\n\nNumber of Fisher Scoring iterations: 23\n\n\n\nFamilias: binomial, poisson, Gamma.\nLinks: logit, log, identity."
  },
  {
    "objectID": "IntroR.html#avaliação-de-modelos",
    "href": "IntroR.html#avaliação-de-modelos",
    "title": "Caderno FIP606",
    "section": "5.3 Avaliação de Modelos",
    "text": "5.3 Avaliação de Modelos\n\nAnálise de resíduos: plot(modelo), DHARMa para GLMs.\nCritérios de informação: AIC(modelo), BIC(modelo).\nValidação cruzada: caret::train() ou tidymodels."
  },
  {
    "objectID": "IntroR.html#agrupamento-com-split-lapply-by-e-tapply",
    "href": "IntroR.html#agrupamento-com-split-lapply-by-e-tapply",
    "title": "Caderno FIP606",
    "section": "6.1 Agrupamento com split, lapply, by e tapply",
    "text": "6.1 Agrupamento com split, lapply, by e tapply\n\nsplit(): divide dados em grupos:\n\niris_split &lt;- split(iris, iris$Species)\n\nlapply(): aplica função a cada elemento:\n\nmedia_sepala &lt;- lapply(iris_split, function(df) mean(df$Sepal.Length))\n\nby(): aplica função por grupos em data frame:\n\nby(data = iris$Sepal.Length, INDICES = iris$Species, FUN = mean)\n\niris$Species: setosa\n[1] 5.006\n------------------------------------------------------------ \niris$Species: versicolor\n[1] 5.936\n------------------------------------------------------------ \niris$Species: virginica\n[1] 6.588\n\n\ntapply(): aplica função a subsets de um vetor:\n\ntapply(iris$Sepal.Length, iris$Species, mean)\n\n    setosa versicolor  virginica \n     5.006      5.936      6.588"
  },
  {
    "objectID": "IntroR.html#loops",
    "href": "IntroR.html#loops",
    "title": "Caderno FIP606",
    "section": "6.2 Loops",
    "text": "6.2 Loops\n\nfor:\n\nfor (i in 1:5) {\n  print(i^2)\n}\n\n[1] 1\n[1] 4\n[1] 9\n[1] 16\n[1] 25\n\n\nwhile:\n\ncont &lt;- 1\nwhile (cont &lt;= 5) {\n  print(cont)\n  cont &lt;- cont + 1\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nrepeat (até break):\n\nrepeat {\n  val &lt;- runif(1)\n  if (val &gt; 0.9) {\n    print(val)\n    break\n  }\n}\n\n[1] 0.9448881"
  },
  {
    "objectID": "IntroR.html#condicionais",
    "href": "IntroR.html#condicionais",
    "title": "Caderno FIP606",
    "section": "6.3 Condicionais",
    "text": "6.3 Condicionais\n\nif / else:\n\nx &lt;- -3\nif (x &gt; 0) {\n  message(\"Positivo\")\n} else if (x == 0) {\n  message(\"Zero\")\n} else {\n  message(\"Negativo\")\n}\n\nifelse() (vetorizado):\n\nx &lt;- c(-1, 0, 1)\nresultado &lt;- ifelse(x &gt; 0, \"Positivo\", \"Não positivo\")\nresultado\n\n[1] \"Não positivo\" \"Não positivo\" \"Positivo\""
  },
  {
    "objectID": "IntroR.html#boas-práticas",
    "href": "IntroR.html#boas-práticas",
    "title": "Caderno FIP606",
    "section": "6.4 Boas Práticas",
    "text": "6.4 Boas Práticas\n\nPrefira funções vetorizadas (apply, lapply, sapply) em vez de loops explícitos.\nUse nomes descritivos e indentação consistente.\nEvite aninhamentos profundos; crie funções para lógicas complexas."
  },
  {
    "objectID": "GLMs.html",
    "href": "GLMs.html",
    "title": "Modelos",
    "section": "",
    "text": "Modelos lineares generalizados\nOs modelos lineares generalizados permitem a modelagem de variáveis respostas que não seguem a distribuição normal. São necessáio definir três componentes básico:\n\nDistribuição da probabilidade: padrão de distribuição da variábel resposta. De acordo com a natureza da variável sua distribuição adota comportamentos distinto, sendo necessário respeitar essa distribuição. Por exemplo: Dados contínuos com variância constante seguem a distruibuição gaussiana/normal. Dados de contagem/frequência seguem a distribuição de Poisson. Dados de probabilidade seguem a distribuição binomial.\nPreditor linear: Combinação das variáveis preditoras e seus respectivos coeficientes.\n\\[\n\\eta = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p\n\\]\nFunção de ligação: É a função monotônica que relaciona o preditor linear a média da distribuição, garantindo que o valor predito permaneça dentro da distribuição por meio da tranformação do valor.\nIdentidade (Gaussiana)\n\\[\ng(\\mu) = \\eta\n\\]\nLog (Poisson)\n\n\\[\ng(\\mu) = \\log(\\mu)\n\\]\n\nLogito (Binomial)\n\n\\[\ng(\\mu) = \\log\\left( \\frac{\\mu}{1 - \\mu} \\right)\n\\]\n\nlibrary(DHARMa)\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(car)\nlibrary(performance)\nlibrary(gsheet)\nlibrary(ggplot2)\nlibrary(agricolae)\nlibrary(epifitter)\nlibrary(dplyr)\nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(drc)\nlibrary(ec50estimator)\n\nInicialmente vamos verificar o comportamento e homogenidade das variâncias, para confirmar que os métodos paramétricos não podem ser adotados. Dessa vamos utilizaremos o DHARMa para visualização dos pressupostos.\n\nInsectsDataframe = InsectSprays\nInsectsDataframe |&gt;\n  ggplot(aes(spray, count))+\n  geom_boxplot(outlier.color=NULL)+\n  geom_jitter(width=0.1)\n\n\n\n\n\n\n\nInsectLM = lm(count ~ spray, data=InsectsDataframe)\nplot(simulateResiduals(InsectLM))\n\n\n\n\n\n\n\nshapiro.test(residuals(InsectLM))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(InsectLM)\nW = 0.96006, p-value = 0.02226\n\n\nAjustando um glm com a distribuição Poisson, adequada a natureza do conjuto de dados, podemos indetificar os grupos distintos de inseticidas.\n\nInsectGLM= glm(count ~spray, data = InsectsDataframe, family=poisson)\nmediasGLM = emmeans(InsectGLM, ~spray, type=(\"response\"))\ncld(mediasGLM)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  1    \n E      3.50 0.540 Inf      2.59      4.74  12   \n D      4.92 0.640 Inf      3.81      6.35   2   \n A     14.50 1.100 Inf     12.50     16.82    3  \n B     15.33 1.130 Inf     13.27     17.72    3  \n F     16.67 1.180 Inf     14.51     19.14    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncheck_model(InsectGLM)\n\n\n\n\n\n\n\nsummary(InsectGLM)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson, data = InsectsDataframe)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.67415    0.07581  35.274  &lt; 2e-16 ***\nsprayB       0.05588    0.10574   0.528    0.597    \nsprayC      -1.94018    0.21389  -9.071  &lt; 2e-16 ***\nsprayD      -1.08152    0.15065  -7.179 7.03e-13 ***\nsprayE      -1.42139    0.17192  -8.268  &lt; 2e-16 ***\nsprayF       0.13926    0.10367   1.343    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\nModelos Mistos\nModelos mistos permitem trabalharmos com dois diferentes tipos de efeitos ao mesmo tempo. Efeitos fixos, são os efeitos a nível de população cujo impacto sobre a resposta buscamos compreender, esses efeitos deve persistir ao longo das repetições uma vez que não são fonte de aleatoriedade. Efeitos aleatórios, representam fontes de variabilidade que não são de interesse, indicando assim a tendência de variação ao longo de níves de agrupamento.\nA utilização de modelos mistos auxiliam a evitar a consideração equivocada de amostras independentes, quando na realidade não são, denominado erro de “pseud-replicação”. Ao tratar a população como um todo levando a um exagerado grau de liberdade e p-valor, levando a conclusões equivocadas. Os modelos mistos são capazes de reconhecer a estrutura de correlação entre os agrupamentos, evitando estimativas enviesadas dos coeficientes dos efeitos fixos.\nDe forma simplificada, são estimados simultaneamente os coeficientes globais para cada variável preditora dos efeitos fixos, enquanto se é predito o desvio dos coeficientes estimados em cada grupo em relação aos coeficientes globais. Ocorre então um ajuste, “encolhimento”, em que os valores de coeficientes são ajustados para minimizar o desvio reduzindo a variância total.\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{Z}\\boldsymbol{u} + \\boldsymbol{\\epsilon}, \\quad \\boldsymbol{u} \\sim \\mathcal{N}(\\mathbf{0},\\,\\mathbf{G}), \\quad \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0},\\,\\mathbf{R})\n\\]\n\\[\n\\begin{array}{ll}\\hline\\text{Símbolo} & \\text{Definição} \\\\\\hline\\mathbf{y} & \\text{vetor de observações (n×1), }E(\\mathbf{y}) = \\mathbf{X}\\boldsymbol{\\beta}\\\\\\mathbf{X} & \\text{matriz de projeto dos efeitos fixos (n×p)}\\\\\\boldsymbol{\\beta} & \\text{parâmetros dos efeitos fixos (p×1), estimados via ML/REML}\\\\\\mathbf{Z} & \\text{matriz de projeto dos efeitos aleatórios (n×q)}\\\\\\mathbf{u} & \\text{efeitos aleatórios (q×1), }E(\\mathbf{u})=0,\\,\\mathrm{Var}(\\mathbf{u})=\\mathbf{G}\\\\\\boldsymbol{\\epsilon} & \\text{erros residuais (n×1), }E(\\boldsymbol{\\epsilon})=0,\\,\\mathrm{Var}(\\boldsymbol{\\epsilon})=\\mathbf{R}\\\\\\mathbf{G} & \\text{matriz de covariância dos efeitos aleatórios (q×q)}\\\\\\mathbf{R} & \\text{matriz de covariância dos erros residuais (n×n)}\\\\\\hline\\end{array}\n\\]\nPara exemplificar, consideremos o conjuto de dados abaixo em que foi observada a produtividade de cada híbrido sob dois diferentes métodos, em um experimento dirigido em estrutura DBC.\n\nCornDf = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1345524759#gid=1345524759\")\nCornDf\n\n# A tibble: 48 × 5\n   hybrid   block method index yield\n   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 30F53 HX     1 pin     21.1 12920\n 2 30F53 HX     2 pin     21.1  9870\n 3 30F53 HX     3 pin     23.3  8920\n 4 30F53 HX     4 pin     35.6 13120\n 5 30F53 YH     1 pin     21.1 12060\n 6 30F53 YH     2 pin     22.2  7860\n 7 30F53 YH     3 pin     27.3  7410\n 8 30F53 YH     4 pin     27.8 10300\n 9 30K64        1 pin     20   11700\n10 30K64        2 pin     20   10700\n# ℹ 38 more rows\n\n\nPodemos tratar os blocos como fator aleatório de forma a minimizar o impactos da variabilidade entre blocos nas estimativas. Enquanto avaliamos a influência do efeito fixos index, hybrid e a interação dos mesmo.\n\nCornDf$Id = interaction(CornDf$hybrid, CornDf$block)\nMCorn = lmer(index ~hybrid*method + (1|block:Id), data=CornDf)\ncar::Anova(MCorn)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        11.4239  5    0.04359 * \nmethod         4.6964  1    0.03023 * \nhybrid:method 15.8062  5    0.00742 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(simulateResiduals(MCorn))\n\n\n\n\n\n\n\nCornDf$predicted &lt;- predict(MCorn)\n\nUtilizando a tabela Anova, podemos identificar quais efeitos fixos apresentaram diferenças significativas, e utilizando a biblioteca DHARMa podemos visualizar a normalide e homocedasticidade dos resíduos.\nSeguindo a investigação podemos verificar quais híbridos apresentaram se distinguem entre si, em função do método.\n\nCornMeans = emmeans(MCorn, ~hybrid | method)\ncld(CornMeans, Letters = letters)\n\nmethod = pin:\n hybrid   emmean   SE   df lower.CL upper.CL .group\n BG7049H    19.4 3.57 24.9     12.1     26.8  a    \n 30K64      20.6 3.57 24.9     13.2     27.9  a    \n 30F53 YH   24.6 3.57 24.9     17.3     31.9  ab   \n 30F53 HX   25.3 3.57 24.9     17.9     32.6  ab   \n 30S31YH    32.5 3.57 24.9     25.2     39.8  ab   \n 30S31H     38.1 3.57 24.9     30.8     45.4   b   \n\nmethod = silk:\n hybrid   emmean   SE   df lower.CL upper.CL .group\n BG7049H    19.2 3.57 24.9     11.8     26.5  a    \n 30K64      21.5 3.57 24.9     14.2     28.8  a    \n 30F53 HX   25.0 3.57 24.9     17.7     32.3  a    \n 30F53 YH   26.2 3.57 24.9     18.9     33.6  a    \n 30S31H     26.5 3.57 24.9     19.2     33.8  a    \n 30S31YH    26.6 3.57 24.9     19.3     34.0  a    \n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nOu então como os métodos se distinguem entre si em função do híbrido.\n\nCornMeans = emmeans(MCorn, ~method | hybrid)\ncld(CornMeans, Letters = letters)\n\nhybrid = 30F53 HX:\n method emmean   SE   df lower.CL upper.CL .group\n silk     25.0 3.57 24.9     17.7     32.3  a    \n pin      25.3 3.57 24.9     17.9     32.6  a    \n\nhybrid = 30F53 YH:\n method emmean   SE   df lower.CL upper.CL .group\n pin      24.6 3.57 24.9     17.3     31.9  a    \n silk     26.2 3.57 24.9     18.9     33.6  a    \n\nhybrid = 30K64:\n method emmean   SE   df lower.CL upper.CL .group\n pin      20.6 3.57 24.9     13.2     27.9  a    \n silk     21.5 3.57 24.9     14.2     28.8  a    \n\nhybrid = 30S31H:\n method emmean   SE   df lower.CL upper.CL .group\n silk     26.5 3.57 24.9     19.2     33.8  a    \n pin      38.1 3.57 24.9     30.8     45.4   b   \n\nhybrid = 30S31YH:\n method emmean   SE   df lower.CL upper.CL .group\n silk     26.6 3.57 24.9     19.3     34.0  a    \n pin      32.5 3.57 24.9     25.2     39.8  a    \n\nhybrid = BG7049H:\n method emmean   SE   df lower.CL upper.CL .group\n silk     19.2 3.57 24.9     11.8     26.5  a    \n pin      19.4 3.57 24.9     12.1     26.8  a    \n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\nModelos Não Lineares\nModelos não lineares são utilizados quando a relação entre a variável resposta e os preditores não pode ser adequadamente representada por uma combinação linear simples, mesmo após transformações. Diferentemente dos modelos lineares e generalizados, nesses modelos a forma funcional entre as variáveis é explicitamente não linear, podendo envolver exponenciais, logaritmos, polinômios de grau maior, funções sigmoides, entre outras.\nA modelagem não linear envolve a especificação de uma função paramétrica, cujo ajuste é feito geralmente por métodos iterativos de otimização, como mínimos quadrados não lineares ou máxima verossimilhança.\nComo exemplo vamos trabalhar com um conjunto de dados em que é avaliada a sensibilidade a fungicidas, a partir da contagem de germinação. Naturalmente esse tipo de dado é não linear, adotando um comportamento logístico. Vamos considerar a germinação média entre as reptições e analisar somente um fungicida para maior simplicidade. Para ajuste do modelo utilizaremos a função drm(), especificiando que deve-se utilizar o modelo log logistico (LL.3)\n\nFungicideSensibility = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=465348652#gid=465348652\")\n\nFungicideSensibility |&gt; \n  group_by(code, dose) |&gt;\n  summarise(germinationMean = mean(germination)) |&gt;\n  ggplot(aes(dose, germinationMean))+\n  geom_point()+\n  facet_wrap(~code)\n\n\n\n\n\n\n\nFGT43 = FungicideSensibility |&gt; \n  group_by(code, dose) |&gt;\n  summarise(germinationMean = mean(germination)) |&gt;\n  filter(code==\"FGT43\")\nFGT43Model = drm(germinationMean ~dose,\n                 data=FGT43,\n                 fct=LL.3())\nplot(FGT43Model)\n\n\n\n\n\n\n\nsummary(FGT43Model)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  1.219692   0.175081  6.9664  0.006069 ** \nd:(Intercept) 48.486911   1.456007 33.3013 5.952e-05 ***\ne:(Intercept)  0.495895   0.060851  8.1494  0.003864 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.636105 (3 degrees of freedom)\n\nAIC(FGT43Model)\n\n[1] 26.7762\n\n\nComo um complemento podemos utilizar a já estabelecida referência de dose efetiva para reduzir 50% para comparar os fungicidas. Utilizando a função estimate_EC50()\n\nEC50Df = estimate_EC50(germination ~ dose,\n              data=FungicideSensibility,\n              isolate_col = \"code\",\n              strata_col = \"state\",\n              interval = \"delta\",\n              fct= drc::LL.3())\nEC50Df|&gt;\n  ggplot(aes(reorder(ID,Estimate), Estimate))+\n  geom_point()+\n  coord_flip()"
  },
  {
    "objectID": "AnáliseInferencial_NParam.html",
    "href": "AnáliseInferencial_NParam.html",
    "title": "Análise Não Paramétrica",
    "section": "",
    "text": "Os testes não paramétricos são procedimentos estatísticos que não exigem suposições estritas sobre a forma da distribuição dos dados (por exemplo, normalidade). Em vez de trabalharem diretamente com valores observados, muitos deles se baseiam em rankings (posições relativas) ou em contagens de concordâncias/discordâncias, tornando-os mais robustos a outliers, assimetrias ou pequenas amostras. Podemos distinguilos entre pareados ou não pareados em função da depêndencia das amostras.\n\n# Importação de bibliotecas\nlibrary(gsheet)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(report)\nlibrary(rstatix)\nlibrary(ggpubr)\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(multcompView)\nlibrary(agricolae)\nlibrary(dplyr)\n\n\n\n\n\n\nUtilizando o teste de wilcoxon podemos identificar se há diferença entre dois grupos com observações indepentes ou depentes. A partir da combinação de dois grupos ordena-se um ranking total, e proseggue com a investigação a partir da soma dos ranking dos respectivos grupos.\nNa versão pareada, são rankeadas as diferenças diferentes de 0 entre cada par. Então é realizada a soma das diferenças positivas e negativas, adotando o menor valor. Para conjunto pequenos (até 25 observações) utiliza-se a tabela de Wilcoxon para determinar o p-valor. Para grandes conjuntos adota-se a aproximação normal.\n\\[\nd_i = x_i - y_i,\\quad i=1,\\dots,n \\\\ \\\\R_i : \\text{posto de }|d_i|\n\\]\n\\[\nW = \\sum_{d_i&gt;0} R_i,\\]\n\\[\nW = \\min(W^+,W^-)\n\\]\nUtilizando um conjunto de dados em que foi observado uma classificação por múltiplos avaliadores com e sem auxílio de uma escala, podemos exemplificar a aplicação de um teste de willcox pareado para identificarmos se houve diferença na performance da avaliação mediante ao uso da escala. Antes de execução do teste podemos averiguar que não há homocedasticidade ou distribuição normal do conjunto de dados, utilizando o teste F e o teste de Shapiro Wilk. Prosseguindo com o teste de Wilcox pareado, podemos observar que há diferença significativa entre os grupos.\n\nScaleDataframe = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1729131173#gid=1729131173\")\n\nUnaided = ScaleDataframe %&gt;%\n  filter(assessment==\"Unaided\") %&gt;%\n  dplyr::select(acuracia) %&gt;%\n  pull()\n\nAided = ScaleDataframe %&gt;%\n  filter(assessment==\"Aided1\") %&gt;%\n  dplyr::select(acuracia) %&gt;%\n  pull()\n\nvar.test(Unaided, Aided)\n\n\n    F test to compare two variances\n\ndata:  Unaided and Aided\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\nshapiro.test(Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  Unaided\nW = 0.7748, p-value = 0.007155\n\nshapiro.test(Aided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  Aided\nW = 0.92852, p-value = 0.4335\n\nwilcox.test(Unaided, Aided, paired=TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  Unaided and Aided\nV = 0, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nUtilizando um conjunto de dados relacionado a contagem de insetos após explosição a inseticidas utilizaremos o wilcox não pareado para verificar se há diferença entre o spray A e o C. Seguindo o protocolo demonstrado anteriormente, iremos averiguar a normalidade dos resíduos do modelo ajustado pelo teste de Anova utilizando o teste de Shapiro Wilk. Ao observarmos um p-valor menor que 0.05, constatamos que os resíduos não seguem a distribuição normal, invalidando o uso de Anova.\n\nInsectsDataframe = InsectSprays\nInsectsDataframe |&gt;\n  ggplot(aes(spray, count))+\n  geom_boxplot(outlier.color=NULL)+\n  geom_jitter(width=0.1)\n\n\n\n\n\n\n\nAnovaModel &lt;- aov(count ~ spray, data = InsectsDataframe)\nhist(residuals(AnovaModel), main = \"Histograma dos Resíduos\",\n     xlab='Resíduos', ylab = 'Frequência')\n\n\n\n\n\n\n\nshapiro.test(residuals(AnovaModel))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(AnovaModel)\nW = 0.96006, p-value = 0.02226\n\n\nDessa forma um alternativa seria utilizar o teste de Willcoxon não pareado. Na sua versão não pareada, a partir das somas dos ranking de cada grupo (R) é calculado U , adotando o menor valor de U encontrado obtem-se o p-valor a partir da distribuição de U. Como teste compara somente dois grupos, podemos selecionar dois inseticidas e compara-los. Observando que há diferença entre os inseticidas A e C.\n\\[ U_1 \\;=\\; n_1\\,n_2 \\;+\\; \\frac{n_1\\,(n_1 + 1)}{2} \\;-\\; R_1 \\]\n\\[ ou \\]\n\\[ U_2 \\;=\\; n_1\\,n_2 \\;+\\; \\frac{n_2\\,(n_2 + 1)}{2} \\;-\\; R_2 \\]\n\\[\nU = \\min(U_1,U_2)\n\\]\n\nInsectsDataframe = InsectSprays\nSprayA = InsectsDataframe |&gt;\n  filter(spray==\"A\") |&gt;\n  dplyr::select(count) |&gt;\n  pull()\n\nSprayC = InsectsDataframe |&gt;\n  filter(spray==\"C\") |&gt;\n  dplyr::select(count) |&gt;\n  pull()\n\nwilcox.test(SprayA, SprayC, paired=FALSE)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  SprayA and SprayC\nW = 143.5, p-value = 3.836e-05\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\n\n\nO teste de Kruskall-Wallis permite a comparação de mais de 2 grupos, que não atendem a distribuição normal. Para possibilitar a comparação, ao invés de comprar os valores, performa a organização de todos valores em ranking, e compara a soma do ranking de cada grupo. A hipótese nula (H0) considera que os grupos são iguais, enquanto a hipótese alternativa (H1) considera que há diferença em algum dos grupos. A soma dos ranking ao quadrado divida pelo número de obbservações do respectivo grupo, é normalizada por uma constante construida a partir do número total de observações, e subtraida por um termo de correção que visa centralizar a distribuição de forma em que sob condições de H0 H é igual a aproximadamente.\n\\[\nH = \\frac{12}{N(N+1)} \\sum_{i=1}^{k} \\frac{R_i^2}{n_i} - 3(N+1)\n\\]\nO valor de H implica sobre a diferença entre a soma dos rankings, ao ser comparado a uma distribuição chi-quadrado com grau de liberdade k-1. Obtendo assim um p-valor, caso menor do que alfa rejeita-se H0, e afirma-se que há ao menos uma grupo distinto.\n\nInsectsDataframe = InsectSprays\nkruskal(InsectsDataframe$count, InsectsDataframe$spray, group=TRUE, console=TRUE)\n\n\nStudy: InsectsDataframe$count ~ InsectsDataframe$spray\nKruskal-Wallis test's\nTies or no Ties\n\nCritical Value: 54.69134\nDegrees of freedom: 5\nPvalue Chisq  : 1.510845e-10 \n\nInsectsDataframe$spray,  means of the ranks\n\n  InsectsDataframe.count  r\nA               52.16667 12\nB               54.83333 12\nC               11.45833 12\nD               25.58333 12\nE               19.33333 12\nF               55.62500 12\n\nPost Hoc Analysis\n\nt-Student: 1.996564\nAlpha    : 0.05\nMinimum Significant Difference: 8.462804 \n\nTreatments with the same letter are not significantly different.\n\n  InsectsDataframe$count groups\nF               55.62500      a\nB               54.83333      a\nA               52.16667      a\nD               25.58333      b\nE               19.33333     bc\nC               11.45833      c"
  },
  {
    "objectID": "AnáliseInferencial_NParam.html#análise-inferencial-não-paramétrica",
    "href": "AnáliseInferencial_NParam.html#análise-inferencial-não-paramétrica",
    "title": "Análise Não Paramétrica",
    "section": "",
    "text": "Os testes não paramétricos são procedimentos estatísticos que não exigem suposições estritas sobre a forma da distribuição dos dados (por exemplo, normalidade). Em vez de trabalharem diretamente com valores observados, muitos deles se baseiam em rankings (posições relativas) ou em contagens de concordâncias/discordâncias, tornando-os mais robustos a outliers, assimetrias ou pequenas amostras. Podemos distinguilos entre pareados ou não pareados em função da depêndencia das amostras.\n\n# Importação de bibliotecas\nlibrary(gsheet)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(report)\nlibrary(rstatix)\nlibrary(ggpubr)\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(multcompView)\nlibrary(agricolae)\nlibrary(dplyr)\n\n\n\n\n\n\nUtilizando o teste de wilcoxon podemos identificar se há diferença entre dois grupos com observações indepentes ou depentes. A partir da combinação de dois grupos ordena-se um ranking total, e proseggue com a investigação a partir da soma dos ranking dos respectivos grupos.\nNa versão pareada, são rankeadas as diferenças diferentes de 0 entre cada par. Então é realizada a soma das diferenças positivas e negativas, adotando o menor valor. Para conjunto pequenos (até 25 observações) utiliza-se a tabela de Wilcoxon para determinar o p-valor. Para grandes conjuntos adota-se a aproximação normal.\n\\[\nd_i = x_i - y_i,\\quad i=1,\\dots,n \\\\ \\\\R_i : \\text{posto de }|d_i|\n\\]\n\\[\nW = \\sum_{d_i&gt;0} R_i,\\]\n\\[\nW = \\min(W^+,W^-)\n\\]\nUtilizando um conjunto de dados em que foi observado uma classificação por múltiplos avaliadores com e sem auxílio de uma escala, podemos exemplificar a aplicação de um teste de willcox pareado para identificarmos se houve diferença na performance da avaliação mediante ao uso da escala. Antes de execução do teste podemos averiguar que não há homocedasticidade ou distribuição normal do conjunto de dados, utilizando o teste F e o teste de Shapiro Wilk. Prosseguindo com o teste de Wilcox pareado, podemos observar que há diferença significativa entre os grupos.\n\nScaleDataframe = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1729131173#gid=1729131173\")\n\nUnaided = ScaleDataframe %&gt;%\n  filter(assessment==\"Unaided\") %&gt;%\n  dplyr::select(acuracia) %&gt;%\n  pull()\n\nAided = ScaleDataframe %&gt;%\n  filter(assessment==\"Aided1\") %&gt;%\n  dplyr::select(acuracia) %&gt;%\n  pull()\n\nvar.test(Unaided, Aided)\n\n\n    F test to compare two variances\n\ndata:  Unaided and Aided\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\nshapiro.test(Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  Unaided\nW = 0.7748, p-value = 0.007155\n\nshapiro.test(Aided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  Aided\nW = 0.92852, p-value = 0.4335\n\nwilcox.test(Unaided, Aided, paired=TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  Unaided and Aided\nV = 0, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nUtilizando um conjunto de dados relacionado a contagem de insetos após explosição a inseticidas utilizaremos o wilcox não pareado para verificar se há diferença entre o spray A e o C. Seguindo o protocolo demonstrado anteriormente, iremos averiguar a normalidade dos resíduos do modelo ajustado pelo teste de Anova utilizando o teste de Shapiro Wilk. Ao observarmos um p-valor menor que 0.05, constatamos que os resíduos não seguem a distribuição normal, invalidando o uso de Anova.\n\nInsectsDataframe = InsectSprays\nInsectsDataframe |&gt;\n  ggplot(aes(spray, count))+\n  geom_boxplot(outlier.color=NULL)+\n  geom_jitter(width=0.1)\n\n\n\n\n\n\n\nAnovaModel &lt;- aov(count ~ spray, data = InsectsDataframe)\nhist(residuals(AnovaModel), main = \"Histograma dos Resíduos\",\n     xlab='Resíduos', ylab = 'Frequência')\n\n\n\n\n\n\n\nshapiro.test(residuals(AnovaModel))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(AnovaModel)\nW = 0.96006, p-value = 0.02226\n\n\nDessa forma um alternativa seria utilizar o teste de Willcoxon não pareado. Na sua versão não pareada, a partir das somas dos ranking de cada grupo (R) é calculado U , adotando o menor valor de U encontrado obtem-se o p-valor a partir da distribuição de U. Como teste compara somente dois grupos, podemos selecionar dois inseticidas e compara-los. Observando que há diferença entre os inseticidas A e C.\n\\[ U_1 \\;=\\; n_1\\,n_2 \\;+\\; \\frac{n_1\\,(n_1 + 1)}{2} \\;-\\; R_1 \\]\n\\[ ou \\]\n\\[ U_2 \\;=\\; n_1\\,n_2 \\;+\\; \\frac{n_2\\,(n_2 + 1)}{2} \\;-\\; R_2 \\]\n\\[\nU = \\min(U_1,U_2)\n\\]\n\nInsectsDataframe = InsectSprays\nSprayA = InsectsDataframe |&gt;\n  filter(spray==\"A\") |&gt;\n  dplyr::select(count) |&gt;\n  pull()\n\nSprayC = InsectsDataframe |&gt;\n  filter(spray==\"C\") |&gt;\n  dplyr::select(count) |&gt;\n  pull()\n\nwilcox.test(SprayA, SprayC, paired=FALSE)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  SprayA and SprayC\nW = 143.5, p-value = 3.836e-05\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\n\n\nO teste de Kruskall-Wallis permite a comparação de mais de 2 grupos, que não atendem a distribuição normal. Para possibilitar a comparação, ao invés de comprar os valores, performa a organização de todos valores em ranking, e compara a soma do ranking de cada grupo. A hipótese nula (H0) considera que os grupos são iguais, enquanto a hipótese alternativa (H1) considera que há diferença em algum dos grupos. A soma dos ranking ao quadrado divida pelo número de obbservações do respectivo grupo, é normalizada por uma constante construida a partir do número total de observações, e subtraida por um termo de correção que visa centralizar a distribuição de forma em que sob condições de H0 H é igual a aproximadamente.\n\\[\nH = \\frac{12}{N(N+1)} \\sum_{i=1}^{k} \\frac{R_i^2}{n_i} - 3(N+1)\n\\]\nO valor de H implica sobre a diferença entre a soma dos rankings, ao ser comparado a uma distribuição chi-quadrado com grau de liberdade k-1. Obtendo assim um p-valor, caso menor do que alfa rejeita-se H0, e afirma-se que há ao menos uma grupo distinto.\n\nInsectsDataframe = InsectSprays\nkruskal(InsectsDataframe$count, InsectsDataframe$spray, group=TRUE, console=TRUE)\n\n\nStudy: InsectsDataframe$count ~ InsectsDataframe$spray\nKruskal-Wallis test's\nTies or no Ties\n\nCritical Value: 54.69134\nDegrees of freedom: 5\nPvalue Chisq  : 1.510845e-10 \n\nInsectsDataframe$spray,  means of the ranks\n\n  InsectsDataframe.count  r\nA               52.16667 12\nB               54.83333 12\nC               11.45833 12\nD               25.58333 12\nE               19.33333 12\nF               55.62500 12\n\nPost Hoc Analysis\n\nt-Student: 1.996564\nAlpha    : 0.05\nMinimum Significant Difference: 8.462804 \n\nTreatments with the same letter are not significantly different.\n\n  InsectsDataframe$count groups\nF               55.62500      a\nB               54.83333      a\nA               52.16667      a\nD               25.58333      b\nE               19.33333     bc\nC               11.45833      c"
  },
  {
    "objectID": "AnáliseExploratória.html",
    "href": "AnáliseExploratória.html",
    "title": "Análise exploratória",
    "section": "",
    "text": "Análise exploratória consiste em um processo preliminar de investigação estatística em que se busca compreender o comportamento/distribuição do conjunto de dados. Através da avaliação da qualidade do conjunto, identificação de padrões, tendência, relações entre as variáveis e verificações de respectivas premissas que precisam ser atendidas em função dos métodos estatísticos a serem utilizados.\n\n\nSumarização estatística:\n\nTendência central: Auxilia na identificação da concentração dos dados.\n\nMédia: Medida sensível as valores do conjunto, obtida pela divisão da soma dos valores pelo número de elementos. Sendo assim um valor representativo do conjunto.\nMediana: Valor que separa a distribuição dos dados em 50%. Auxiliando na interpretação de distribuições assimétricas.\nModa: Valor que aparecem que com mais frequência.\n\nDispersão: Mede a variabilidade do dados em torno da tendência central.\n\nAmplitude: Espectro de valores limitados pelos valores extremos\nVariância: Dispersão em torno da média. Obtida pela média dos quadrados da diferença em relação a média.\nDesvio padrão: Dispersão em torno da média na mesma undidade do conjunto de dados, facilitando a interpretação. Obtida pela raiz quadrada da variância.\n\n\nDistribuição: Comportamento da frequência dos valores ao longo da amplitude\n\nSimetria: Proporção/tendência da distribuição. Simétria ou assimétrica.\nModalidade: Caracterização em função dos picos de frequência. Unimodal, bimodal, multimodal.\n\nRelação:\n\nCorrelação: Intesidade e direção da relação entre duas variáveis.\nTendências: Variação dos valores ao longo de uma dimensão.\n\n\n# Importação de bibliotecas\nlibrary(agricolae) \nlibrary(tidyverse)\n\n# Input de conjunto de dados\ndata(\"greenhouse\")\nDataframe &lt;- greenhouse[[2]]\n\n\n\n\nCalculo das métricas de tendência central e dispersão\n\nWeightMean = mean(Dataframe$weight)\nprint(paste('Média: ', WeightMean))\n\n[1] \"Média:  751.23125\"\n\nWeightMedian = median(Dataframe$weight)\nprint(paste('Mediana: ', WeightMedian))\n\n[1] \"Mediana:  659.8\"\n\nModa &lt;- as.numeric(names(which.max(table(Dataframe$weight))))\nprint(paste(\"Moda:\", Moda))\n\n[1] \"Moda: 284\"\n\n\n\nVariance = var(Dataframe$weight)\nprint(paste(\"Variância:\", Variance))\n\n[1] \"Variância: 87341.5192154255\"\n\nStandardDeviation = sd(Dataframe$weight)\nprint(paste(\"Desvio Padrão:\", StandardDeviation))\n\n[1] \"Desvio Padrão: 295.53598632895\"\n\n\n\n\n\nPlotagem de gráficos (histograma e boxplot), permitem a visualização da tendência central e distribuição de forma mais intuitiva.\n\n# Histograma\nggplot(Dataframe, aes(x = weight)) +\n  geom_histogram(binwidth = 20, fill = \"#69b3a2\", color = \"black\") +\n  facet_wrap(~ method) +\n  labs(\n    title = \"Distribuição de Peso por Método\",\n    x = \"Peso\",\n    y = \"Frequência\"\n  )\n\n\n\n\n\n\n\n\n\n# Boxplot\nggplot(Dataframe, aes(x = method, y = weight, fill = method)) +\n  geom_boxplot() +\n  geom_jitter(width=0.1)+\n  labs(\n    title = \"Boxplot do Peso por Método\",\n    x = \"Método\",\n    y = \"Peso\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Gráfico de linha das médias por tratamento ao longo das avaliações\ndata(disease)\n\nDisease &lt;- pivot_longer(\n  disease,\n  cols = c(E2, E5, E7),\n  names_to = \"Evaluation\",\n  values_to = \"Severity\"\n)\n\nDisease$Evaluation &lt;- factor(Disease$Evaluation, levels = c(\"E2\", \"E5\", \"E7\"))\n\nggplot(Disease, aes(x = Evaluation, y = Severity, group = trt, color = trt)) +\n  stat_summary(geom = \"line\", fun = mean, size = 1) +\n  stat_summary(geom = \"point\", fun = mean, size = 2) +\n  labs(\n    title = \"Progressão da Severidade da Doença ao Longo do Tempo\",\n    x = \"Tempo de Avaliação\",\n    y = \"Severidade Média\",\n    color = \"Tratamento\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nDisease &lt;- disease %&gt;%\n  mutate(severity_mean = rowMeans(select(., E2, E5, E7)))\n\nCorrelation &lt;- cor(Disease$severity_mean, disease$yield, method = \"pearson\")\nprint(paste('Correlação entre produtividade e severidade: ', Correlation))\n\n[1] \"Correlação entre produtividade e severidade:  -0.72490150241725\"\n\nggplot(Disease, aes(x = severity_mean, y = yield)) +\n  geom_point(color = \"#1f77b4\", size = 2) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"black\") +\n  labs(\n    title = \"Correlação entre Severidade Média da Doença e Produtividade\",\n    x = \"Severidade Média da Doença\",\n    y = \"Produtividade (Yield)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nComo um exemplo mais aplicados utilizamos a função audpc() da biblioteca agricolae. Que permite o cálulo da área abaixo da curva da severidade ao longo do tempo, assim podemos comparar o resultado entre os tratamentos e identificar quais sofreram menor severidade durante o período avaliado. Como 3 repetições por tratamentos iremos comparar a média entres as repetições de cada tratamento, enquanto o desvio padrão entre as repetições pode nos fornecer uma idea da variação entre as repetições auxiliando a investigar se em alguma avalição houve valores muito discrepantes.\n\ndias &lt;- c(2, 5, 7)\n\ndisease$AUDPC &lt;- apply(disease[, c(\"E2\", \"E5\", \"E7\")], 1, function(sev) {\n  audpc(sev, dias)\n})\n\nAUDC_Dataframe &lt;- disease %&gt;%\n  group_by(trt) %&gt;%\n  summarise(\n    AUDC_Média = mean(AUDPC),\n    Desvio_Padrão = sd(AUDPC),\n    n = n()\n  ) %&gt;%\n  arrange(AUDC_Média)\n\nprint(AUDC_Dataframe)\n\n# A tibble: 7 × 4\n  trt   AUDC_Média Desvio_Padrão     n\n  &lt;fct&gt;      &lt;dbl&gt;         &lt;dbl&gt; &lt;int&gt;\n1 T5          14.8         22.2      3\n2 T6          18           11.7      3\n3 T3          22            7.37     3\n4 T4          25.2         25.5      3\n5 T2          38.7         13.7      3\n6 T1          44.7          7.49     3\n7 T0          80.8         20.1      3"
  },
  {
    "objectID": "AnáliseExploratória.html#análise-exploratória",
    "href": "AnáliseExploratória.html#análise-exploratória",
    "title": "Análise exploratória",
    "section": "",
    "text": "Análise exploratória consiste em um processo preliminar de investigação estatística em que se busca compreender o comportamento/distribuição do conjunto de dados. Através da avaliação da qualidade do conjunto, identificação de padrões, tendência, relações entre as variáveis e verificações de respectivas premissas que precisam ser atendidas em função dos métodos estatísticos a serem utilizados.\n\n\nSumarização estatística:\n\nTendência central: Auxilia na identificação da concentração dos dados.\n\nMédia: Medida sensível as valores do conjunto, obtida pela divisão da soma dos valores pelo número de elementos. Sendo assim um valor representativo do conjunto.\nMediana: Valor que separa a distribuição dos dados em 50%. Auxiliando na interpretação de distribuições assimétricas.\nModa: Valor que aparecem que com mais frequência.\n\nDispersão: Mede a variabilidade do dados em torno da tendência central.\n\nAmplitude: Espectro de valores limitados pelos valores extremos\nVariância: Dispersão em torno da média. Obtida pela média dos quadrados da diferença em relação a média.\nDesvio padrão: Dispersão em torno da média na mesma undidade do conjunto de dados, facilitando a interpretação. Obtida pela raiz quadrada da variância.\n\n\nDistribuição: Comportamento da frequência dos valores ao longo da amplitude\n\nSimetria: Proporção/tendência da distribuição. Simétria ou assimétrica.\nModalidade: Caracterização em função dos picos de frequência. Unimodal, bimodal, multimodal.\n\nRelação:\n\nCorrelação: Intesidade e direção da relação entre duas variáveis.\nTendências: Variação dos valores ao longo de uma dimensão.\n\n\n# Importação de bibliotecas\nlibrary(agricolae) \nlibrary(tidyverse)\n\n# Input de conjunto de dados\ndata(\"greenhouse\")\nDataframe &lt;- greenhouse[[2]]\n\n\n\n\nCalculo das métricas de tendência central e dispersão\n\nWeightMean = mean(Dataframe$weight)\nprint(paste('Média: ', WeightMean))\n\n[1] \"Média:  751.23125\"\n\nWeightMedian = median(Dataframe$weight)\nprint(paste('Mediana: ', WeightMedian))\n\n[1] \"Mediana:  659.8\"\n\nModa &lt;- as.numeric(names(which.max(table(Dataframe$weight))))\nprint(paste(\"Moda:\", Moda))\n\n[1] \"Moda: 284\"\n\n\n\nVariance = var(Dataframe$weight)\nprint(paste(\"Variância:\", Variance))\n\n[1] \"Variância: 87341.5192154255\"\n\nStandardDeviation = sd(Dataframe$weight)\nprint(paste(\"Desvio Padrão:\", StandardDeviation))\n\n[1] \"Desvio Padrão: 295.53598632895\"\n\n\n\n\n\nPlotagem de gráficos (histograma e boxplot), permitem a visualização da tendência central e distribuição de forma mais intuitiva.\n\n# Histograma\nggplot(Dataframe, aes(x = weight)) +\n  geom_histogram(binwidth = 20, fill = \"#69b3a2\", color = \"black\") +\n  facet_wrap(~ method) +\n  labs(\n    title = \"Distribuição de Peso por Método\",\n    x = \"Peso\",\n    y = \"Frequência\"\n  )\n\n\n\n\n\n\n\n\n\n# Boxplot\nggplot(Dataframe, aes(x = method, y = weight, fill = method)) +\n  geom_boxplot() +\n  geom_jitter(width=0.1)+\n  labs(\n    title = \"Boxplot do Peso por Método\",\n    x = \"Método\",\n    y = \"Peso\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Gráfico de linha das médias por tratamento ao longo das avaliações\ndata(disease)\n\nDisease &lt;- pivot_longer(\n  disease,\n  cols = c(E2, E5, E7),\n  names_to = \"Evaluation\",\n  values_to = \"Severity\"\n)\n\nDisease$Evaluation &lt;- factor(Disease$Evaluation, levels = c(\"E2\", \"E5\", \"E7\"))\n\nggplot(Disease, aes(x = Evaluation, y = Severity, group = trt, color = trt)) +\n  stat_summary(geom = \"line\", fun = mean, size = 1) +\n  stat_summary(geom = \"point\", fun = mean, size = 2) +\n  labs(\n    title = \"Progressão da Severidade da Doença ao Longo do Tempo\",\n    x = \"Tempo de Avaliação\",\n    y = \"Severidade Média\",\n    color = \"Tratamento\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nDisease &lt;- disease %&gt;%\n  mutate(severity_mean = rowMeans(select(., E2, E5, E7)))\n\nCorrelation &lt;- cor(Disease$severity_mean, disease$yield, method = \"pearson\")\nprint(paste('Correlação entre produtividade e severidade: ', Correlation))\n\n[1] \"Correlação entre produtividade e severidade:  -0.72490150241725\"\n\nggplot(Disease, aes(x = severity_mean, y = yield)) +\n  geom_point(color = \"#1f77b4\", size = 2) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"black\") +\n  labs(\n    title = \"Correlação entre Severidade Média da Doença e Produtividade\",\n    x = \"Severidade Média da Doença\",\n    y = \"Produtividade (Yield)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nComo um exemplo mais aplicados utilizamos a função audpc() da biblioteca agricolae. Que permite o cálulo da área abaixo da curva da severidade ao longo do tempo, assim podemos comparar o resultado entre os tratamentos e identificar quais sofreram menor severidade durante o período avaliado. Como 3 repetições por tratamentos iremos comparar a média entres as repetições de cada tratamento, enquanto o desvio padrão entre as repetições pode nos fornecer uma idea da variação entre as repetições auxiliando a investigar se em alguma avalição houve valores muito discrepantes.\n\ndias &lt;- c(2, 5, 7)\n\ndisease$AUDPC &lt;- apply(disease[, c(\"E2\", \"E5\", \"E7\")], 1, function(sev) {\n  audpc(sev, dias)\n})\n\nAUDC_Dataframe &lt;- disease %&gt;%\n  group_by(trt) %&gt;%\n  summarise(\n    AUDC_Média = mean(AUDPC),\n    Desvio_Padrão = sd(AUDPC),\n    n = n()\n  ) %&gt;%\n  arrange(AUDC_Média)\n\nprint(AUDC_Dataframe)\n\n# A tibble: 7 × 4\n  trt   AUDC_Média Desvio_Padrão     n\n  &lt;fct&gt;      &lt;dbl&gt;         &lt;dbl&gt; &lt;int&gt;\n1 T5          14.8         22.2      3\n2 T6          18           11.7      3\n3 T3          22            7.37     3\n4 T4          25.2         25.5      3\n5 T2          38.7         13.7      3\n6 T1          44.7          7.49     3\n7 T0          80.8         20.1      3"
  },
  {
    "objectID": "AnáliseInferencial.html",
    "href": "AnáliseInferencial.html",
    "title": "Análise paramétrica",
    "section": "",
    "text": "A estatística inferencial é o ramo da estatística responsável por permitir a inferência de conclusões sobre uma população com base na análise de uma amostra representativa. A inferência ocorre a partir do teste de hipoteses, que evidencia a diferença entre os fatores comparados. Amparado pelo valor de P, probabilidade da hipótese nula obter um resultado tão extremo quanto o observado. Além dos testes, a estatística inferencial inclui métodos de estimativa de parâmetros e intervalos de confiança, e fornece compreensão sobre sobre o efeito de preditores e gerar predições. Podemos classificar os teste entre paramétricos e não paramétricos baseados nas suposições sobre os dados que são requeridas para que sejam aplicados. Os paramétricos requerem que a distruição dos dados siga um padrão conhecido, enquanto os não paramétricos não requerem uma distribuição específica.\nPara aprendermos sobre estatítica inferencial paramétrica, vamos utilizar o conjunto de dados que contém o tamanho de colônias de fungos de diferentes espécies. Buscaremos identificar se há diferença entre as espécies, utilizando o teste T, Anova e teste de PosHoc\n\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(report)\nlibrary(rstatix)\nlibrary(gsheet)\nlibrary(emmeans)\nlibrary(multcompView)\nlibrary(multcomp)\nlibrary(agricolae)\nlibrary(DT)\nlibrary(DHARMa)\n\nMiceliaDataframe = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=959387827#gid=959387827\")\nMiceliaDataframe\n\n# A tibble: 30 × 3\n   especie   rep   tcm\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 Fasi        1  1.5 \n 2 Fasi        2  1.59\n 3 Fasi        3  1.52\n 4 Fasi        4  1.52\n 5 Fasi        5  1.6 \n 6 Fasi        6  1.7 \n 7 Faus        1  1.52\n 8 Faus        2  1.25\n 9 Faus        3  1.27\n10 Faus        4  1.3 \n# ℹ 20 more rows\n\n\n\n\nMétodo estatístico paramétrico que visa identificar se há diferença significativa entre três ou mais grupos independentes, por comparação da variância. Possibilitando distinguir se a variação (Soma do quadrado dos resíduos), é explicada por aleatoriedade (Soma do quadrado dos resíduos em relação a média dos grupos) ou por características distinta dos grupos (Soma do quadrado dos resíduos em relação a média total).\nSoma do quadrado dos resíduos:\nResíduos são a diferença entre o valor observado e uma média. Seja em relação a média total ou dentro de um grupo\n\\[\ne_i \\;=\\; y_i \\;-\\; \\hat y_i\n\\]\n\\[\n\\begin{align*}e_i &\\quad \\text{é o resíduo da i-ésima observação (erro de predição)} \\\\y_i &\\quad \\text{é o valor observado da i-ésima observação} \\\\\\hat{y}_i &\\quad \\text{é o valor previsto pelo modelo para a i-ésima observação}\\end{align*}\n\\]\n\nmean_global &lt;- mean(MiceliaDataframe$tcm)\nMiceliaDataframe %&gt;%\n  ggplot(aes(x = especie, y = tcm)) +\n  geom_boxplot(outlier.colour = NA) +\n  geom_jitter(aes(color = especie), width = 0.2) +\n  stat_summary(\n    aes(shape = \"Média por Espécie\"),\n    fun    = mean,\n    geom   = \"point\",\n    size   = 3,\n    color  = \"black\",\n    fill   = \"black\"\n  ) +\n  geom_hline(\n    aes(\n      yintercept = mean_global,\n      linetype   = \"Média Global\"\n    ),\n    color = \"black\",\n    size  = 0.7\n  ) +\n  scale_shape_manual(\n    name   = \"\",\n    values = c(\"Média por Espécie\" = 16)\n  ) +\n  scale_linetype_manual(\n    name   = \"\",\n    values = c(\"Média Global\" = \"solid\")\n  ) +\n  guides(\n    shape    = guide_legend(override.aes = list(linetype = 0)),\n    linetype = guide_legend(override.aes = list(shape    = NA))\n  )\n\n\n\n\n\n\n\n\nElevando o resíduo ao quadrado almejamos a evidenciar grandes discrepâncias, a garantir que a soma total será uma mensuração de variabilidade absoluta e permite maior conveniência matemática. Uma vez que será uma função convexa conhecida dos parâmetros do modelo.\nPortanto podemos compreender a soma do quadrado dos resíduo como uma mensuração do quanto da variabilidade não é explicada pelo modelo.\n\\[\nSQR_{\\mathrm{res}}\n\\;=\\;\n\\sum_{i=1}^n e_i^2\n\\;=\\;\n\\sum_{i=1}^n (y_i - \\hat y_i)^2\n\\]\n\\[\n\\begin{align*}SQR_{\\mathrm{res}} &\\quad \\text{é a Soma dos Quadrados dos Resíduos} \\\\\\sum_{i=1}^n &\\quad \\text{indica a soma para todas as observações de i = 1 até n} \\\\e_i &\\quad \\text{é o resíduo da i-ésima observação (} e_i = y_i - \\hat{y}_i \\text{)} \\\\y_i &\\quad \\text{é o valor observado da i-ésima observação} \\\\\\hat{y}_i &\\quad \\text{é o valor previsto pelo modelo para a i-ésima observação} \\\\n &\\quad \\text{é o número total de observações}\\end{align*}\n\\]\nObtemos o valor de F através da razão entre a diferença entre as somas dos quadrados dos resíduos (SQR) divido pela diferença entre número de parâmetros dos modelos (P), e a SQR(grupo) dividido pela diferença entre o número de amostras pelo número de parâmetros do modelos da média total. F demostra a relação entre variabilidade entre os grupos e a aleatoriedade, dado a varibilidade interna de cada grupo. Portanto quando a variância explicada é maior que a variância não explicada F &gt; 1 ao menos um possui diferença significativa.\n\\[\nF = \\frac{\\text{Variância explicada}}{\\text{Variância não explicada}} =\n\\frac{\n  \\displaystyle \\frac{SS(\\text{mean}) - SS(\\text{fit})}{P(\\text{fit}) - P(\\text{mean})}\n}{\n  \\displaystyle \\frac{SS(\\text{fit})}{n - P(\\text{fit})}\n}\n\\]O P-valor indicada a probabilidade de observar essa variabilidade ou outra ainda mais extrema, no caso de hipótese nula (H0: sem diferença entre grupos). Portanto ao obtermos um pequeno P-valor temos uma probabilidade baixa o suficiente para recursarmos H0 e adotarmos a hipótese alternativa (H1: há ao menos um grupo com diferença significativa), interpretando o como o fenômeno que ocorreu é improvável de ocorrer sob a condições de H0. O p-valor é obtido pela área abaixo da curva de distribuição de F, na qual temos a densidade de probabilidade em função dos valores de F, integrando os valores mais extremos que o F encontrado.\n\n\n\n\n\n\n\nAntes da aplicação de testes inferenciais, é essencial verificar se os dados atendem às suposições exigidas pelos modelos estatísticos. No caso da Anova as principais suposições são:\n\nNormalidade dos resíduos, avaliada por meio de testes como o Shapiro-Wilk e por inspeção visual de histogramas;\nHomogeneidade de variâncias entre os grupos, verificada por testes como F de Fisher (para duas amostras) ou Bartlett (para múltiplos grupos);\nIndependência das observações, que garante que os valores analisados não estejam correlacionados entre si.\n\nA validação dessas suposições assegura a confiabilidade dos resultados e evita conclusões equivocadas.\n\n\n\nComo passos iniciais da análise, vamos ajustar um modelo de análise da variância com a função aov(). Com o objetivo de avaliar se há diferença significativa entre o valor da variável ‘tcm’ de cada ‘espécie’.\nPara validar o uso do modelo, vamos verificar se os resíduos (diferenças entre as observações e os preditos) seguem a distribuição normal. A verificação pode ser feita de maneira visual, através do histograma dos resíduos. Ou de forma mais analítica como o teste de shapiro-wilk, que considera como hipotese nula que o comportamento difere da normalidade. Sendo assim necessário obter um P-valor maior do que Alfa (0.05) para confirmar a normalidade.\n\n# Teste de normalidade dos resíduos do modelo\nAnovaModel &lt;- aov(tcm ~ especie, data = MiceliaDataframe)\nhist(residuals(AnovaModel), main = \"Histograma dos Resíduos\",\n     xlab='Resíduos', ylab = 'Frequência')\n\n\n\n\n\n\n\nshapiro.test(residuals(AnovaModel))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(AnovaModel)\nW = 0.9821, p-value = 0.8782\n\n\n\n\n\nOutra suposição necessária para validar a aplicação do teste de Anova, é a homogenidade das variâncias. Uma teste comum que permite essa averiguação é o teste de bartlett, em que a hipótese nula assume que as variâncias dos tratamentos são iguais. Caso p-valor seja maior que alfa (0.05), confirmamos a homocedasticidade.\n\n# Teste de homogeneidade de variância\nbartlett.test(tcm ~ especie, data = MiceliaDataframe)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\n\n\n\n\nA tabela de análise Anova, permite a avaliação dos resultados e performance do teste. Através dela podemos observar o grau de liberdade, soma e média dos quadrados dos resíduos, valor de F e P.\n\nsummary(AnovaModel)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nespecie      4 1.4696  0.3674   19.63 2.03e-07 ***\nResiduals   25 0.4679  0.0187                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nApós análise de variância, e a detecção de que há diferenças significativas, seguimos investigando para identificar quas grupos são diferentes entre si. Para isso sçao comumente aplicados testes de Post-hoc, realizam a comparação todas as combinações possíveis entre os grupos enquanto se controla a chance de ocorrer falsos positivos ao ajustar o nível de significância.\nComo exemplo vamos utilizar EMMs (média marginal estimada) que utiliza médias ajustadas, corrigindo desequilíbrios no número de observações e efeito de covariáveis. *\nPara facilitar a visualização, vamos organizar os grupo identificando-os como letras (a,b,c)\n\n# Comparação de médias com EMMeans\nem &lt;- emmeans(AnovaModel, ~ especie)\ncld(em, Letters = letters)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  a    \n Faus     1.237 0.0559 25    1.122     1.35   b   \n Fcor     1.322 0.0559 25    1.207     1.44   b   \n Fmer     1.427 0.0559 25    1.312     1.54   bc  \n Fasi     1.572 0.0559 25    1.457     1.69    c  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\nCaso o conjunto de valores não siga a normalidade, uma alternativa é transformar os dados. Ajustando sua distribuição a normalidade. Utilizando o mesmo conjunto de dados iremos utilizar a raiz quadrada como forma de ajuste. A raiz quadrada permite a “compressão” dos valores de maneira proporcional a grandeza do valor, ajustando a simetria da distribuição. A analisarmos a distribuição dos resíduos novamente, podemos observar que foi averguado que os resíduos agora seguem a normalidade e homocedasticidade.\n\nInsectsDataframe = InsectSprays\nInsectLM = lm(sqrt(count) ~ spray, data=InsectsDataframe)\nplot(simulateResiduals(InsectLM))\n\n\n\n\n\n\n\nshapiro.test(residuals(InsectLM))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(InsectLM)\nW = 0.98721, p-value = 0.6814\n\nMeans = emmeans(InsectLM, ~ spray)\ncld(Means)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95 \nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\nA Anova fatorial de dois fatores (Two‑Way ANOVA) estende a ideia da análise de variância unidirecional para investigar simultaneamente o efeito de duas variáveis categóricas sobre uma variável resposta contínua, bem como a existência de interação entre elas. Enquanto na Anova simples comparamos apenas médias de um fator, na Anova fatorial avaliamos:\n\nEfeito principal de cada fator — se diferentes níveis levam, isoladamente, a diferenças significativas.\n\nInteração entre fatores — se o impacto de um fator depende do nível do outro.\n\nNo exemplo abaixo iremos utilizar um conjunto de dados para investigar o efeito e diferentes doses de fungicidas diferentes sob a severidade. Ajustando um modelo linear com interação entre os fatores dose e tratamento, podemos observar que os resíduos atendem as pressuposições, e observar a tabela de análise de variâncai indicando que houve diferença significativa entre os grupos da variável ‘treat’, ‘dose’ e da interação entre as duas.\n\nFungicideDataframe = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=2023059672#gid=2023059672\")\n\nFungicideDataframe |&gt;\n  ggplot(aes(factor(dose), severity*100))+\n  geom_boxplot(outlier.color=NULL)+\n  geom_jitter(width=0.1)+\n  facet_wrap(~treat)\n\n\n\n\n\n\n\n#\nMFungicide = lm(severity ~treat*dose, data=FungicideDataframe)\nhist(residuals(MFungicide))\n\n\n\n\n\n\n\nplot(simulateResiduals(MFungicide))\n\n\n\n\n\n\n\nanova(MFungicide)\n\nAnalysis of Variance Table\n\nResponse: severity\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat       1 0.113232 0.113232  30.358 4.754e-05 ***\ndose        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:dose  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals  16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n# Visualizing significance interaction\nggplot(FungicideDataframe, aes(x = dose, y = severity*100, \n                                group = treat, color = treat)) +\n  stat_summary(fun = mean, geom = \"line\") +           # linhas de tendência\n  stat_summary(fun = mean, geom = \"point\", shape = 16) + # pontos médios\n  stat_summary(fun.data = mean_se, geom = \"errorbar\", width = 0.1) + # barras de erro (SE)\n  scale_color_brewer(palette = \"Set1\", name = \"Tratamento\") +\n  labs(\n    x     = \"Dose\",\n    y     = \"Severidade (%)\",\n    title = \"Interação entre Dose e Tratamento na Severidade\",\n    caption = \"Médias com intervalo de erro padrão\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    legend.position = \"top\",\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(face = \"bold\", hjust = 0.5)\n  )\n\n\n\n\n\n\n\n\nPara finalizar podemos identificar os grupos que apresentaram diferenças significativas, por nível de tratamento ou dose.\n\nMediasFungicideByDose = emmeans(MFungicide, ~treat|dose)\ncld(MediasFungicideByDose, Letters = letters)\n\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789  a    \n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500   b   \n\ndose = 2.0:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781  a    \n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080  a    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nMediasFungicideByTreat = emmeans(MFungicide, ~dose|treat)\ncld(MediasFungicideByTreat, Letters = letters)\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  a    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   b   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  a    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  a    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\nOu método comum para identificar se há diferença significativa entre médias é o teste T de Student. No teste T um valor de T é obtido e comparado a um valor tabelo em função do número de graus de liberdade. Caso o T valor seja maior que o valor crítico tabelado, a hipótese nula é rejeita (H0: Não há diferença significativa), adotando a hipótese alternativa de que há diferença significativa (H1).\n\n\nSua forma independente requer amostras que não exersem influência entre si, ou seja não há relação entre os valores. O valor de T é obtido através da razão entre a difereça das médias pelo erro padrão agrupado.\n\\[\n\\begin{align*}t &= \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}} \\\\\\\\\\ \\\\\\bar{X}_1 &\\quad \\text{é a média da amostra do grupo 1} \\\\\\bar{X}_2 &\\quad \\text{é a média da amostra do grupo 2} \\\\s_1^2 &\\quad \\text{é a variância da amostra do grupo 1} \\\\s_2^2 &\\quad \\text{é a variância da amostra do grupo 2} \\\\n_1 &\\quad \\text{é o tamanho da amostra do grupo 1} \\\\n_2 &\\quad \\text{é o tamanho da amostra do grupo 2} \\\\t &\\quad \\text{é o valor do teste t calculado}\\end{align*}\n\\]\nComo exemplo vamos utilizar um conjunto de dados com observaçõs de comprimento com e sem o uso de Mg2. Inicalmente vamos verificar a normalidade de homogenidade das variâncias, averiguando que os dados seguem a distribuição normal e os grupos possuem variância homogenea.\n\nMgDataframe &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137\")\nMgDataframeWide &lt;- MgDataframe |&gt; \n  pivot_wider(names_from = trat, values_from = comp)\n\nshapiro.test(MgDataframeWide$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  MgDataframeWide$control\nW = 0.93886, p-value = 0.5404\n\nshapiro.test(MgDataframeWide$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  MgDataframeWide$Mg2\nW = 0.97269, p-value = 0.9146\n\nvar.test(MgDataframeWide$control, MgDataframeWide$Mg2)\n\n\n    F test to compare two variances\n\ndata:  MgDataframeWide$control and MgDataframeWide$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\n\nEm seguida vamos performar o test t independent para verificar se houve diferença significativa entre os grupos. Constatando que há diferença entre os grupos.\n\nTResult_base &lt;- t.test(\n  MgDataframeWide$control,\n  MgDataframeWide$Mg2,\n  var.equal = TRUE\n)\ntidy(TResult_base)\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic    p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     5.16      15.7      10.5      8.15    1.86e-7        18     3.83      6.49\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n\n\n\n\nAmostras pareadas envolvem observações relacionadas em pares, onde cada elemento de um grupo está diretamente vinculado a um elemento do outro grupo.\nSeu valor de T é obtido pela equação abaixo:\n\n\\[\n\\begin{align*}t &= \\frac{\\bar{d}}{s_d / \\sqrt{n}}  \\\\\\bar{d} &\\quad \\text{é a média das diferenças entre os pares de observações} \\\\s_d &\\quad \\text{é o desvio padrão das diferenças} \\\\n &\\quad \\text{é o número de pares de observações} \\\\t &\\quad \\text{é o valor do teste t calculado}\\end{align*}\n\\]\nPara ilustrar o teste T pareado vamos utilizar um conjunto de dados em que diferentes avaliadores realizaram classificações com e sem o auxílio de escala. É preciso somente verificar se a diferença entre as observações pareadas seguem a normalidade e o teste pode ser executado. Conforme podemos observar que houve diferença significativa\n\n\nScaleDataframe &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1729131173#gid=1729131173\")\n\nUnaided &lt;- ScaleDataframe |&gt; filter(assessment == \"Unaided\") |&gt; pull(acuracia)\nAided   &lt;- ScaleDataframe |&gt; filter(assessment == \"Aided1\")  |&gt; pull(acuracia)\n\ndifferences &lt;- Unaided - Aided\nshapiro.test(differences)\n\n\n    Shapiro-Wilk normality test\n\ndata:  differences\nW = 0.858, p-value = 0.07227\n\nScaleTTest &lt;- t.test(\n  Unaided,\n  Aided,\n  paired  = TRUE,\n  var.equal = FALSE\n)\ntidy(ScaleTTest)\n\n# A tibble: 1 × 8\n  estimate statistic p.value parameter conf.low conf.high method     alternative\n     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      \n1   -0.235     -4.42 0.00167         9   -0.355    -0.115 Paired t-… two.sided"
  },
  {
    "objectID": "AnáliseInferencial.html#análise-inferencial",
    "href": "AnáliseInferencial.html#análise-inferencial",
    "title": "Análise paramétrica",
    "section": "",
    "text": "A estatística inferencial é o ramo da estatística responsável por permitir a inferência de conclusões sobre uma população com base na análise de uma amostra representativa. A inferência ocorre a partir do teste de hipoteses, que evidencia a diferença entre os fatores comparados. Amparado pelo valor de P, probabilidade da hipótese nula obter um resultado tão extremo quanto o observado. Além dos testes, a estatística inferencial inclui métodos de estimativa de parâmetros e intervalos de confiança, e fornece compreensão sobre sobre o efeito de preditores e gerar predições. Podemos classificar os teste entre paramétricos e não paramétricos baseados nas suposições sobre os dados que são requeridas para que sejam aplicados. Os paramétricos requerem que a distruição dos dados siga um padrão conhecido, enquanto os não paramétricos não requerem uma distribuição específica.\nPara aprendermos sobre estatítica inferencial paramétrica, vamos utilizar o conjunto de dados que contém o tamanho de colônias de fungos de diferentes espécies. Buscaremos identificar se há diferença entre as espécies, utilizando o teste T, Anova e teste de PosHoc\n\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(report)\nlibrary(rstatix)\nlibrary(gsheet)\nlibrary(emmeans)\nlibrary(multcompView)\nlibrary(multcomp)\nlibrary(agricolae)\nlibrary(DT)\nlibrary(DHARMa)\n\nMiceliaDataframe = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=959387827#gid=959387827\")\nMiceliaDataframe\n\n# A tibble: 30 × 3\n   especie   rep   tcm\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 Fasi        1  1.5 \n 2 Fasi        2  1.59\n 3 Fasi        3  1.52\n 4 Fasi        4  1.52\n 5 Fasi        5  1.6 \n 6 Fasi        6  1.7 \n 7 Faus        1  1.52\n 8 Faus        2  1.25\n 9 Faus        3  1.27\n10 Faus        4  1.3 \n# ℹ 20 more rows\n\n\n\n\nMétodo estatístico paramétrico que visa identificar se há diferença significativa entre três ou mais grupos independentes, por comparação da variância. Possibilitando distinguir se a variação (Soma do quadrado dos resíduos), é explicada por aleatoriedade (Soma do quadrado dos resíduos em relação a média dos grupos) ou por características distinta dos grupos (Soma do quadrado dos resíduos em relação a média total).\nSoma do quadrado dos resíduos:\nResíduos são a diferença entre o valor observado e uma média. Seja em relação a média total ou dentro de um grupo\n\\[\ne_i \\;=\\; y_i \\;-\\; \\hat y_i\n\\]\n\\[\n\\begin{align*}e_i &\\quad \\text{é o resíduo da i-ésima observação (erro de predição)} \\\\y_i &\\quad \\text{é o valor observado da i-ésima observação} \\\\\\hat{y}_i &\\quad \\text{é o valor previsto pelo modelo para a i-ésima observação}\\end{align*}\n\\]\n\nmean_global &lt;- mean(MiceliaDataframe$tcm)\nMiceliaDataframe %&gt;%\n  ggplot(aes(x = especie, y = tcm)) +\n  geom_boxplot(outlier.colour = NA) +\n  geom_jitter(aes(color = especie), width = 0.2) +\n  stat_summary(\n    aes(shape = \"Média por Espécie\"),\n    fun    = mean,\n    geom   = \"point\",\n    size   = 3,\n    color  = \"black\",\n    fill   = \"black\"\n  ) +\n  geom_hline(\n    aes(\n      yintercept = mean_global,\n      linetype   = \"Média Global\"\n    ),\n    color = \"black\",\n    size  = 0.7\n  ) +\n  scale_shape_manual(\n    name   = \"\",\n    values = c(\"Média por Espécie\" = 16)\n  ) +\n  scale_linetype_manual(\n    name   = \"\",\n    values = c(\"Média Global\" = \"solid\")\n  ) +\n  guides(\n    shape    = guide_legend(override.aes = list(linetype = 0)),\n    linetype = guide_legend(override.aes = list(shape    = NA))\n  )\n\n\n\n\n\n\n\n\nElevando o resíduo ao quadrado almejamos a evidenciar grandes discrepâncias, a garantir que a soma total será uma mensuração de variabilidade absoluta e permite maior conveniência matemática. Uma vez que será uma função convexa conhecida dos parâmetros do modelo.\nPortanto podemos compreender a soma do quadrado dos resíduo como uma mensuração do quanto da variabilidade não é explicada pelo modelo.\n\\[\nSQR_{\\mathrm{res}}\n\\;=\\;\n\\sum_{i=1}^n e_i^2\n\\;=\\;\n\\sum_{i=1}^n (y_i - \\hat y_i)^2\n\\]\n\\[\n\\begin{align*}SQR_{\\mathrm{res}} &\\quad \\text{é a Soma dos Quadrados dos Resíduos} \\\\\\sum_{i=1}^n &\\quad \\text{indica a soma para todas as observações de i = 1 até n} \\\\e_i &\\quad \\text{é o resíduo da i-ésima observação (} e_i = y_i - \\hat{y}_i \\text{)} \\\\y_i &\\quad \\text{é o valor observado da i-ésima observação} \\\\\\hat{y}_i &\\quad \\text{é o valor previsto pelo modelo para a i-ésima observação} \\\\n &\\quad \\text{é o número total de observações}\\end{align*}\n\\]\nObtemos o valor de F através da razão entre a diferença entre as somas dos quadrados dos resíduos (SQR) divido pela diferença entre número de parâmetros dos modelos (P), e a SQR(grupo) dividido pela diferença entre o número de amostras pelo número de parâmetros do modelos da média total. F demostra a relação entre variabilidade entre os grupos e a aleatoriedade, dado a varibilidade interna de cada grupo. Portanto quando a variância explicada é maior que a variância não explicada F &gt; 1 ao menos um possui diferença significativa.\n\\[\nF = \\frac{\\text{Variância explicada}}{\\text{Variância não explicada}} =\n\\frac{\n  \\displaystyle \\frac{SS(\\text{mean}) - SS(\\text{fit})}{P(\\text{fit}) - P(\\text{mean})}\n}{\n  \\displaystyle \\frac{SS(\\text{fit})}{n - P(\\text{fit})}\n}\n\\]O P-valor indicada a probabilidade de observar essa variabilidade ou outra ainda mais extrema, no caso de hipótese nula (H0: sem diferença entre grupos). Portanto ao obtermos um pequeno P-valor temos uma probabilidade baixa o suficiente para recursarmos H0 e adotarmos a hipótese alternativa (H1: há ao menos um grupo com diferença significativa), interpretando o como o fenômeno que ocorreu é improvável de ocorrer sob a condições de H0. O p-valor é obtido pela área abaixo da curva de distribuição de F, na qual temos a densidade de probabilidade em função dos valores de F, integrando os valores mais extremos que o F encontrado.\n\n\n\n\n\n\n\nAntes da aplicação de testes inferenciais, é essencial verificar se os dados atendem às suposições exigidas pelos modelos estatísticos. No caso da Anova as principais suposições são:\n\nNormalidade dos resíduos, avaliada por meio de testes como o Shapiro-Wilk e por inspeção visual de histogramas;\nHomogeneidade de variâncias entre os grupos, verificada por testes como F de Fisher (para duas amostras) ou Bartlett (para múltiplos grupos);\nIndependência das observações, que garante que os valores analisados não estejam correlacionados entre si.\n\nA validação dessas suposições assegura a confiabilidade dos resultados e evita conclusões equivocadas.\n\n\n\nComo passos iniciais da análise, vamos ajustar um modelo de análise da variância com a função aov(). Com o objetivo de avaliar se há diferença significativa entre o valor da variável ‘tcm’ de cada ‘espécie’.\nPara validar o uso do modelo, vamos verificar se os resíduos (diferenças entre as observações e os preditos) seguem a distribuição normal. A verificação pode ser feita de maneira visual, através do histograma dos resíduos. Ou de forma mais analítica como o teste de shapiro-wilk, que considera como hipotese nula que o comportamento difere da normalidade. Sendo assim necessário obter um P-valor maior do que Alfa (0.05) para confirmar a normalidade.\n\n# Teste de normalidade dos resíduos do modelo\nAnovaModel &lt;- aov(tcm ~ especie, data = MiceliaDataframe)\nhist(residuals(AnovaModel), main = \"Histograma dos Resíduos\",\n     xlab='Resíduos', ylab = 'Frequência')\n\n\n\n\n\n\n\nshapiro.test(residuals(AnovaModel))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(AnovaModel)\nW = 0.9821, p-value = 0.8782\n\n\n\n\n\nOutra suposição necessária para validar a aplicação do teste de Anova, é a homogenidade das variâncias. Uma teste comum que permite essa averiguação é o teste de bartlett, em que a hipótese nula assume que as variâncias dos tratamentos são iguais. Caso p-valor seja maior que alfa (0.05), confirmamos a homocedasticidade.\n\n# Teste de homogeneidade de variância\nbartlett.test(tcm ~ especie, data = MiceliaDataframe)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\n\n\n\n\nA tabela de análise Anova, permite a avaliação dos resultados e performance do teste. Através dela podemos observar o grau de liberdade, soma e média dos quadrados dos resíduos, valor de F e P.\n\nsummary(AnovaModel)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nespecie      4 1.4696  0.3674   19.63 2.03e-07 ***\nResiduals   25 0.4679  0.0187                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nApós análise de variância, e a detecção de que há diferenças significativas, seguimos investigando para identificar quas grupos são diferentes entre si. Para isso sçao comumente aplicados testes de Post-hoc, realizam a comparação todas as combinações possíveis entre os grupos enquanto se controla a chance de ocorrer falsos positivos ao ajustar o nível de significância.\nComo exemplo vamos utilizar EMMs (média marginal estimada) que utiliza médias ajustadas, corrigindo desequilíbrios no número de observações e efeito de covariáveis. *\nPara facilitar a visualização, vamos organizar os grupo identificando-os como letras (a,b,c)\n\n# Comparação de médias com EMMeans\nem &lt;- emmeans(AnovaModel, ~ especie)\ncld(em, Letters = letters)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  a    \n Faus     1.237 0.0559 25    1.122     1.35   b   \n Fcor     1.322 0.0559 25    1.207     1.44   b   \n Fmer     1.427 0.0559 25    1.312     1.54   bc  \n Fasi     1.572 0.0559 25    1.457     1.69    c  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\nCaso o conjunto de valores não siga a normalidade, uma alternativa é transformar os dados. Ajustando sua distribuição a normalidade. Utilizando o mesmo conjunto de dados iremos utilizar a raiz quadrada como forma de ajuste. A raiz quadrada permite a “compressão” dos valores de maneira proporcional a grandeza do valor, ajustando a simetria da distribuição. A analisarmos a distribuição dos resíduos novamente, podemos observar que foi averguado que os resíduos agora seguem a normalidade e homocedasticidade.\n\nInsectsDataframe = InsectSprays\nInsectLM = lm(sqrt(count) ~ spray, data=InsectsDataframe)\nplot(simulateResiduals(InsectLM))\n\n\n\n\n\n\n\nshapiro.test(residuals(InsectLM))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(InsectLM)\nW = 0.98721, p-value = 0.6814\n\nMeans = emmeans(InsectLM, ~ spray)\ncld(Means)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95 \nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\nA Anova fatorial de dois fatores (Two‑Way ANOVA) estende a ideia da análise de variância unidirecional para investigar simultaneamente o efeito de duas variáveis categóricas sobre uma variável resposta contínua, bem como a existência de interação entre elas. Enquanto na Anova simples comparamos apenas médias de um fator, na Anova fatorial avaliamos:\n\nEfeito principal de cada fator — se diferentes níveis levam, isoladamente, a diferenças significativas.\n\nInteração entre fatores — se o impacto de um fator depende do nível do outro.\n\nNo exemplo abaixo iremos utilizar um conjunto de dados para investigar o efeito e diferentes doses de fungicidas diferentes sob a severidade. Ajustando um modelo linear com interação entre os fatores dose e tratamento, podemos observar que os resíduos atendem as pressuposições, e observar a tabela de análise de variâncai indicando que houve diferença significativa entre os grupos da variável ‘treat’, ‘dose’ e da interação entre as duas.\n\nFungicideDataframe = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=2023059672#gid=2023059672\")\n\nFungicideDataframe |&gt;\n  ggplot(aes(factor(dose), severity*100))+\n  geom_boxplot(outlier.color=NULL)+\n  geom_jitter(width=0.1)+\n  facet_wrap(~treat)\n\n\n\n\n\n\n\n#\nMFungicide = lm(severity ~treat*dose, data=FungicideDataframe)\nhist(residuals(MFungicide))\n\n\n\n\n\n\n\nplot(simulateResiduals(MFungicide))\n\n\n\n\n\n\n\nanova(MFungicide)\n\nAnalysis of Variance Table\n\nResponse: severity\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat       1 0.113232 0.113232  30.358 4.754e-05 ***\ndose        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:dose  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals  16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n# Visualizing significance interaction\nggplot(FungicideDataframe, aes(x = dose, y = severity*100, \n                                group = treat, color = treat)) +\n  stat_summary(fun = mean, geom = \"line\") +           # linhas de tendência\n  stat_summary(fun = mean, geom = \"point\", shape = 16) + # pontos médios\n  stat_summary(fun.data = mean_se, geom = \"errorbar\", width = 0.1) + # barras de erro (SE)\n  scale_color_brewer(palette = \"Set1\", name = \"Tratamento\") +\n  labs(\n    x     = \"Dose\",\n    y     = \"Severidade (%)\",\n    title = \"Interação entre Dose e Tratamento na Severidade\",\n    caption = \"Médias com intervalo de erro padrão\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    legend.position = \"top\",\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(face = \"bold\", hjust = 0.5)\n  )\n\n\n\n\n\n\n\n\nPara finalizar podemos identificar os grupos que apresentaram diferenças significativas, por nível de tratamento ou dose.\n\nMediasFungicideByDose = emmeans(MFungicide, ~treat|dose)\ncld(MediasFungicideByDose, Letters = letters)\n\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789  a    \n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500   b   \n\ndose = 2.0:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781  a    \n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080  a    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nMediasFungicideByTreat = emmeans(MFungicide, ~dose|treat)\ncld(MediasFungicideByTreat, Letters = letters)\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  a    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   b   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  a    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  a    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\nOu método comum para identificar se há diferença significativa entre médias é o teste T de Student. No teste T um valor de T é obtido e comparado a um valor tabelo em função do número de graus de liberdade. Caso o T valor seja maior que o valor crítico tabelado, a hipótese nula é rejeita (H0: Não há diferença significativa), adotando a hipótese alternativa de que há diferença significativa (H1).\n\n\nSua forma independente requer amostras que não exersem influência entre si, ou seja não há relação entre os valores. O valor de T é obtido através da razão entre a difereça das médias pelo erro padrão agrupado.\n\\[\n\\begin{align*}t &= \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}} \\\\\\\\\\ \\\\\\bar{X}_1 &\\quad \\text{é a média da amostra do grupo 1} \\\\\\bar{X}_2 &\\quad \\text{é a média da amostra do grupo 2} \\\\s_1^2 &\\quad \\text{é a variância da amostra do grupo 1} \\\\s_2^2 &\\quad \\text{é a variância da amostra do grupo 2} \\\\n_1 &\\quad \\text{é o tamanho da amostra do grupo 1} \\\\n_2 &\\quad \\text{é o tamanho da amostra do grupo 2} \\\\t &\\quad \\text{é o valor do teste t calculado}\\end{align*}\n\\]\nComo exemplo vamos utilizar um conjunto de dados com observaçõs de comprimento com e sem o uso de Mg2. Inicalmente vamos verificar a normalidade de homogenidade das variâncias, averiguando que os dados seguem a distribuição normal e os grupos possuem variância homogenea.\n\nMgDataframe &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137\")\nMgDataframeWide &lt;- MgDataframe |&gt; \n  pivot_wider(names_from = trat, values_from = comp)\n\nshapiro.test(MgDataframeWide$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  MgDataframeWide$control\nW = 0.93886, p-value = 0.5404\n\nshapiro.test(MgDataframeWide$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  MgDataframeWide$Mg2\nW = 0.97269, p-value = 0.9146\n\nvar.test(MgDataframeWide$control, MgDataframeWide$Mg2)\n\n\n    F test to compare two variances\n\ndata:  MgDataframeWide$control and MgDataframeWide$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\n\nEm seguida vamos performar o test t independent para verificar se houve diferença significativa entre os grupos. Constatando que há diferença entre os grupos.\n\nTResult_base &lt;- t.test(\n  MgDataframeWide$control,\n  MgDataframeWide$Mg2,\n  var.equal = TRUE\n)\ntidy(TResult_base)\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic    p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     5.16      15.7      10.5      8.15    1.86e-7        18     3.83      6.49\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n\n\n\n\nAmostras pareadas envolvem observações relacionadas em pares, onde cada elemento de um grupo está diretamente vinculado a um elemento do outro grupo.\nSeu valor de T é obtido pela equação abaixo:\n\n\\[\n\\begin{align*}t &= \\frac{\\bar{d}}{s_d / \\sqrt{n}}  \\\\\\bar{d} &\\quad \\text{é a média das diferenças entre os pares de observações} \\\\s_d &\\quad \\text{é o desvio padrão das diferenças} \\\\n &\\quad \\text{é o número de pares de observações} \\\\t &\\quad \\text{é o valor do teste t calculado}\\end{align*}\n\\]\nPara ilustrar o teste T pareado vamos utilizar um conjunto de dados em que diferentes avaliadores realizaram classificações com e sem o auxílio de escala. É preciso somente verificar se a diferença entre as observações pareadas seguem a normalidade e o teste pode ser executado. Conforme podemos observar que houve diferença significativa\n\n\nScaleDataframe &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1729131173#gid=1729131173\")\n\nUnaided &lt;- ScaleDataframe |&gt; filter(assessment == \"Unaided\") |&gt; pull(acuracia)\nAided   &lt;- ScaleDataframe |&gt; filter(assessment == \"Aided1\")  |&gt; pull(acuracia)\n\ndifferences &lt;- Unaided - Aided\nshapiro.test(differences)\n\n\n    Shapiro-Wilk normality test\n\ndata:  differences\nW = 0.858, p-value = 0.07227\n\nScaleTTest &lt;- t.test(\n  Unaided,\n  Aided,\n  paired  = TRUE,\n  var.equal = FALSE\n)\ntidy(ScaleTTest)\n\n# A tibble: 1 × 8\n  estimate statistic p.value parameter conf.low conf.high method     alternative\n     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      \n1   -0.235     -4.42 0.00167         9   -0.355    -0.115 Paired t-… two.sided"
  },
  {
    "objectID": "Compendium.html",
    "href": "Compendium.html",
    "title": "Compendium",
    "section": "",
    "text": "Funções Base do R / Estatísticas\nmean(x, na.rm = FALSE)\nCalcula a média aritmética do vetor numérico x.\nExemplo: mean(c(1,2,3)) → 2\nmedian(x, na.rm = FALSE)\nCalcula a mediana (valor central) do vetor x.\nExemplo: median(c(1,3,2)) → 2\nvar(x, na.rm = FALSE)\nCalcula a variância amostral do vetor x.\nsd(x, na.rm = FALSE)\nCalcula o desvio padrão do vetor x.\nprint(x, ...)\nExibe o valor de x no console.\ntable(..., exclude = NULL, useNA = \"no\")\nCria tabelas de frequência a partir de vetores ou fatores.\nnames(x)\nRetorna ou atribui nomes aos elementos do objeto x.\napply(X, MARGIN, FUN, ...)\nAplica a função FUN às linhas (MARGIN = 1) ou colunas (MARGIN = 2) de uma matriz ou array X.\nrowMeans(x, na.rm = FALSE)\nCalcula a média por linha de uma matriz ou data frame.\nhist(x, breaks, main, xlab, ylab, ...)\nGera um histograma do vetor numérico x.\nshapiro.test(x)\nTeste de normalidade de Shapiro-Wilk para o vetor x.\nHipótese nula: dados seguem distribuição normal.\nvar.test(x, y)\nTesta igualdade de variâncias entre duas amostras x e y.\nwilcox.test(x, y = NULL, paired = FALSE, ...)\nTeste de Wilcoxon (sinalizado se pareado, ou Mann-Whitney U se não pareado) para comparação não paramétrica entre dois grupos.\nkruskal(x, g, ...) (do pacote agricolae)\nTeste de Kruskal-Wallis para comparação de múltiplos grupos não paramétricos.\naov(formula, data, ...)\nAjusta um modelo de análise de variância (ANOVA).\nsummary(object, ...)\nProduz um resumo estatístico de um objeto (ex: modelo ajustado).\nlm(formula, data, ...)\nAjusta um modelo de regressão linear.\nglm(formula, family = ..., data, ...)\nAjusta um modelo linear generalizado (ex: Poisson, binomial).\nplot(x, ...)\nFunção genérica para plotagem.\npredict(object, newdata, ...)\nGera predições a partir de um modelo ajustado.\nAIC(object, ...)\nCalcula o Critério de Informação de Akaike para comparação de modelos.\n\n\nFunções do dplyr / tidyverse\nfilter(.data, ...)\nFiltra linhas baseado em condições.\nExemplo: filter(df, var == \"A\")\nselect(.data, ...)\nSeleciona colunas de um data frame.\npull(.data, var = -1)\nExtrai uma coluna como vetor.\nmutate(.data, ...)\nCria ou modifica colunas em um data frame.\ngroup_by(.data, ...)\nAgrupa dados para operações agrupadas.\nsummarise(.data, ...)\nResume dados (ex: média, soma) em grupos.\n\n\nFunções do ggplot2 para Visualização\nggplot(data, aes(...))\nInicializa um gráfico ggplot com dados e mapeamentos estéticos.\naes(x, y, ...)\nDefine mapeamentos estéticos, como variáveis para x e y.\ngeom_histogram(binwidth, fill, color, ...)\nCria histograma.\ngeom_boxplot(outlier.colour = NULL, ...)\nCria boxplots.\ngeom_jitter(width, height, ...)\nAdiciona pontos com jitter para evitar sobreposição.\nstat_summary(fun, geom, fun.data, ...)\nAdiciona estatísticas resumidas (ex: média, barras de erro).\ngeom_point(shape, size, color, fill, ...)\nAdiciona pontos no gráfico.\ngeom_smooth(method = \"lm\", se = TRUE, ...)\nAdiciona linha de tendência suavizada (modelo linear por padrão).\ngeom_errorbar(width, ...)\nAdiciona barras de erro (ex: erro padrão).\nfacet_wrap(~ var)\nCria subplots por níveis de uma variável.\ncoord_flip()\nInverte os eixos x e y.\nscale_shape_manual(name, values)\nCustomiza formas no gráfico e legenda.\nscale_linetype_manual(name, values)\nCustomiza tipos de linha na legenda.\nguides(...)\nAjusta legendas.\nlabs(title, x, y, color, caption, ...)\nAdiciona títulos, legendas e rótulos.\ntheme(...)\nAjusta elementos visuais do gráfico.\nscale_color_brewer(palette, name)\nAplica paleta de cores do ColorBrewer.\n\n\nFunções para Avaliação de Modelos e Estatística Avançada\ncar::Anova(model, ...)\nRealiza análise de variância tipo II ou III em modelos ajustados.\nDHARMa::simulateResiduals(fittedModel, ...)\nSimula resíduos para diagnóstico de modelos complexos.\nemmeans(object, specs, type = NULL, ...)\nCalcula médias marginais estimadas (least squares means).\ncld(emmGrid, Letters = letters)\nProduz letras compactas para agrupamento em comparações múltiplas.\nestimate_EC50(formula, data, isolate_col, strata_col, interval, fct, ...)\nEstima a dose efetiva EC50 em modelos de dose-resposta.\ndrm(formula, data, fct, ...)\nAjusta modelos de dose-resposta não lineares.\nLL.3()\nFunção log-logística de 3 parâmetros para dose-resposta.\nlmer(formula, data, ...)\nAjusta modelos lineares mistos.\n\n\nVariados\nlibrary(package)\nCarrega um pacote R.\ngsheet2tbl(url)\nImporta dados diretamente de uma planilha Google para um tibble/data frame."
  },
  {
    "objectID": "Index.html",
    "href": "Index.html",
    "title": "Bem vindo!",
    "section": "",
    "text": "Bem-vindo(a) a meu caderno digitalda disciplina de Análise e Visualização de Dados.\nNesse site busquei sintetizar as informações de programação em R e estatística passadas durante a discplina, de forma organizada e didática.\nAbordando os principais conceitos, técnicas e práticas apresentadas ao longo do curso, permitindo que você revisite e aprofunde seus conhecimentos.\nAqui você encontrará:\n\nFundamentos de Análise de Dados: conceitos essenciais sobre tipos de dados, estruturas e estatística descritiva.\nLimpeza e Transformação: estratégias para preparar seus conjuntos de dados, incluindo importação, tratamento de valores faltantes e normalização.\nExploração Visual: introdução a diferentes tipos de gráficos e boas práticas para representar dados.\nCasos Práticos e Exemplos: aplicação dos conceitos em exercícios e projetos que ilustram o fluxo completo de análise, da aquisição ao compartilhamento dos resultados."
  }
]