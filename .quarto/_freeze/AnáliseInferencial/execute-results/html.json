{
  "hash": "8949683cf008baf8ab2dd9dbc8312cef",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Análise paramétrica\"\nwarning: False\n---\n\n\n\n\n## Análise inferencial\n\nA estatística inferencial é o ramo da estatística responsável por permitir a inferência de conclusões sobre uma população com base na análise de uma amostra representativa. A inferência ocorre a partir do teste de hipoteses, que evidencia a diferença entre os fatores comparados. Amparado pelo valor de P, probabilidade da hipótese nula obter um resultado tão extremo quanto o observado. Além dos testes, a estatística inferencial inclui métodos de estimativa de parâmetros e intervalos de confiança, e fornece compreensão sobre sobre o efeito de preditores e gerar predições. Podemos classificar os teste entre paramétricos e não paramétricos baseados nas suposições sobre os dados que são requeridas para que sejam aplicados. Os paramétricos requerem que a distruição dos dados siga um padrão conhecido, enquanto os não paramétricos não requerem uma distribuição específica.\n\nPara aprendermos sobre estatítica inferencial paramétrica, vamos utilizar o conjunto de dados que contém o tamanho de colônias de fungos de diferentes espécies. Buscaremos identificar se há diferença entre as espécies, utilizando o teste T, Anova e teste de PosHoc\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(report)\nlibrary(rstatix)\nlibrary(gsheet)\nlibrary(emmeans)\nlibrary(multcompView)\nlibrary(multcomp)\nlibrary(agricolae)\nlibrary(DT)\nlibrary(DHARMa)\n\nMiceliaDataframe = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=959387827#gid=959387827\")\nMiceliaDataframe\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 30 × 3\n   especie   rep   tcm\n   <chr>   <dbl> <dbl>\n 1 Fasi        1  1.5 \n 2 Fasi        2  1.59\n 3 Fasi        3  1.52\n 4 Fasi        4  1.52\n 5 Fasi        5  1.6 \n 6 Fasi        6  1.7 \n 7 Faus        1  1.52\n 8 Faus        2  1.25\n 9 Faus        3  1.27\n10 Faus        4  1.3 \n# ℹ 20 more rows\n```\n\n\n:::\n:::\n\n\n\n\n### Análise utilizando Anova (analysis of variance)\n\nMétodo estatístico paramétrico que visa identificar se há diferença significativa entre três ou mais grupos independentes, por comparação da variância. Possibilitando distinguir se a variação (Soma do quadrado dos resíduos), é explicada por aleatoriedade (Soma do quadrado dos resíduos em relação a média dos grupos) ou por características distinta dos grupos (Soma do quadrado dos resíduos em relação a média total).\n\n**Soma do quadrado dos resíduos:**\n\nResíduos são a diferença entre o valor observado e uma média. Seja em relação a média total ou dentro de um grupo\n\n$$\ne_i \\;=\\; y_i \\;-\\; \\hat y_i\n$$\n\n$$\n\\begin{align*}e_i &\\quad \\text{é o resíduo da i-ésima observação (erro de predição)} \\\\y_i &\\quad \\text{é o valor observado da i-ésima observação} \\\\\\hat{y}_i &\\quad \\text{é o valor previsto pelo modelo para a i-ésima observação}\\end{align*}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean_global <- mean(MiceliaDataframe$tcm)\nMiceliaDataframe %>%\n  ggplot(aes(x = especie, y = tcm)) +\n  geom_boxplot(outlier.colour = NA) +\n  geom_jitter(aes(color = especie), width = 0.2) +\n  stat_summary(\n    aes(shape = \"Média por Espécie\"),\n    fun    = mean,\n    geom   = \"point\",\n    size   = 3,\n    color  = \"black\",\n    fill   = \"black\"\n  ) +\n  geom_hline(\n    aes(\n      yintercept = mean_global,\n      linetype   = \"Média Global\"\n    ),\n    color = \"black\",\n    size  = 0.7\n  ) +\n  scale_shape_manual(\n    name   = \"\",\n    values = c(\"Média por Espécie\" = 16)\n  ) +\n  scale_linetype_manual(\n    name   = \"\",\n    values = c(\"Média Global\" = \"solid\")\n  ) +\n  guides(\n    shape    = guide_legend(override.aes = list(linetype = 0)),\n    linetype = guide_legend(override.aes = list(shape    = NA))\n  )\n```\n\n::: {.cell-output-display}\n![](AnáliseInferencial_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\nElevando o resíduo ao quadrado almejamos a evidenciar grandes discrepâncias, a garantir que a soma total será uma mensuração de variabilidade absoluta e permite maior conveniência matemática. Uma vez que será uma função convexa conhecida dos parâmetros do modelo.\n\nPortanto podemos compreender a soma do quadrado dos resíduo como uma mensuração do quanto da variabilidade não é explicada pelo modelo.\n\n$$\nSQR_{\\mathrm{res}}\n\\;=\\;\n\\sum_{i=1}^n e_i^2\n\\;=\\;\n\\sum_{i=1}^n (y_i - \\hat y_i)^2\n$$\n\n$$\n\\begin{align*}SQR_{\\mathrm{res}} &\\quad \\text{é a Soma dos Quadrados dos Resíduos} \\\\\\sum_{i=1}^n &\\quad \\text{indica a soma para todas as observações de i = 1 até n} \\\\e_i &\\quad \\text{é o resíduo da i-ésima observação (} e_i = y_i - \\hat{y}_i \\text{)} \\\\y_i &\\quad \\text{é o valor observado da i-ésima observação} \\\\\\hat{y}_i &\\quad \\text{é o valor previsto pelo modelo para a i-ésima observação} \\\\n &\\quad \\text{é o número total de observações}\\end{align*}\n$$\n\nObtemos o valor de F através da razão entre a diferença entre as somas dos quadrados dos resíduos (SQR) divido pela diferença entre número de parâmetros dos modelos (P), e a SQR(grupo) dividido pela diferença entre o número de amostras pelo número de parâmetros do modelos da média total. F demostra a relação entre variabilidade entre os grupos e a aleatoriedade, dado a varibilidade interna de cada grupo. Portanto quando a variância explicada é maior que a variância não explicada F \\> 1 ao menos um possui diferença significativa.\n\n$$\nF = \\frac{\\text{Variância explicada}}{\\text{Variância não explicada}} = \n\\frac{\n  \\displaystyle \\frac{SS(\\text{mean}) - SS(\\text{fit})}{P(\\text{fit}) - P(\\text{mean})}\n}{\n  \\displaystyle \\frac{SS(\\text{fit})}{n - P(\\text{fit})}\n}\n$$O P-valor indicada a probabilidade de observar essa variabilidade ou outra ainda mais extrema, no caso de hipótese nula (H0: sem diferença entre grupos). Portanto ao obtermos um pequeno P-valor temos uma probabilidade baixa o suficiente para recursarmos H0 e adotarmos a hipótese alternativa (H1: há ao menos um grupo com diferença significativa), interpretando o como o fenômeno que ocorreu é improvável de ocorrer sob a condições de H0. O p-valor é obtido pela área abaixo da curva de distribuição de F, na qual temos a densidade de probabilidade em função dos valores de F, integrando os valores mais extremos que o F encontrado.\n\n![](P-valor.gif){fig-alt=\"Ilustração animada do p‑valor\" fig-align=\"center\"}\n\n#### Checagem das premissas\n\nAntes da aplicação de testes inferenciais, é essencial verificar se os dados atendem às suposições exigidas pelos modelos estatísticos. No caso da Anova as principais suposições são:\n\n-   **Normalidade dos resíduos**, avaliada por meio de testes como o *Shapiro-Wilk* e por inspeção visual de histogramas;\n\n-   **Homogeneidade de variâncias** entre os grupos, verificada por testes como *F de Fisher* (para duas amostras) ou *Bartlett* (para múltiplos grupos);\n\n-   **Independência das observações**, que garante que os valores analisados não estejam correlacionados entre si.\n\nA validação dessas suposições assegura a confiabilidade dos resultados e evita conclusões equivocadas.\n\n#### Normalidade\n\nComo passos iniciais da análise, vamos ajustar um modelo de análise da variância com a função aov(). Com o objetivo de avaliar se há diferença significativa entre o valor da variável 'tcm' de cada 'espécie'.\\\nPara validar o uso do modelo, vamos verificar se os resíduos (diferenças entre as observações e os preditos) seguem a distribuição normal. A verificação pode ser feita de maneira visual, através do histograma dos resíduos. Ou de forma mais analítica como o teste de shapiro-wilk, que considera como hipotese nula que o comportamento difere da normalidade. Sendo assim necessário obter um P-valor maior do que Alfa (0.05) para confirmar a normalidade.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Teste de normalidade dos resíduos do modelo\nAnovaModel <- aov(tcm ~ especie, data = MiceliaDataframe)\nhist(residuals(AnovaModel), main = \"Histograma dos Resíduos\",\n     xlab='Resíduos', ylab = 'Frequência')\n```\n\n::: {.cell-output-display}\n![](AnáliseInferencial_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nshapiro.test(residuals(AnovaModel))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  residuals(AnovaModel)\nW = 0.9821, p-value = 0.8782\n```\n\n\n:::\n:::\n\n\n\n\n#### Homocedasticidade\n\nOutra suposição necessária para validar a aplicação do teste de Anova, é a homogenidade das variâncias. Uma teste comum que permite essa averiguação é o teste de bartlett, em que a hipótese nula assume que as variâncias dos tratamentos são iguais. Caso p-valor seja maior que alfa (0.05), confirmamos a homocedasticidade.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Teste de homogeneidade de variância\nbartlett.test(tcm ~ especie, data = MiceliaDataframe)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n```\n\n\n:::\n:::\n\n\n\n\n#### Tabela Anova\n\nA tabela de análise Anova, permite a avaliação dos resultados e performance do teste. Através dela podemos observar o grau de liberdade, soma e média dos quadrados dos resíduos, valor de F e P.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(AnovaModel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nespecie      4 1.4696  0.3674   19.63 2.03e-07 ***\nResiduals   25 0.4679  0.0187                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n### Post-hoc\n\nApós análise de variância, e a detecção de que há diferenças significativas, seguimos investigando para identificar quas grupos são diferentes entre si. Para isso sçao comumente aplicados testes de Post-hoc, realizam a comparação todas as combinações possíveis entre os grupos enquanto se controla a chance de ocorrer falsos positivos ao ajustar o nível de significância.\n\nComo exemplo vamos utilizar EMMs (média marginal estimada) que utiliza médias ajustadas, corrigindo desequilíbrios no número de observações e efeito de covariáveis. \\*\n\nPara facilitar a visualização, vamos organizar os grupo identificando-os como letras (a,b,c)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Comparação de médias com EMMeans\nem <- emmeans(AnovaModel, ~ especie)\ncld(em, Letters = letters)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  a    \n Faus     1.237 0.0559 25    1.122     1.35   b   \n Fcor     1.322 0.0559 25    1.207     1.44   b   \n Fmer     1.427 0.0559 25    1.312     1.54   bc  \n Fasi     1.572 0.0559 25    1.457     1.69    c  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n\n\n### Tranformação dos dados\n\nCaso o conjunto de valores não siga a normalidade, uma alternativa é transformar os dados. Ajustando sua distribuição a normalidade. Utilizando o mesmo conjunto de dados iremos utilizar a raiz quadrada como forma de ajuste. A raiz quadrada permite a \"compressão\" dos valores de maneira proporcional a grandeza do valor, ajustando a simetria da distribuição. A analisarmos a distribuição dos resíduos novamente, podemos observar que foi averguado que os resíduos agora seguem a normalidade e homocedasticidade.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nInsectsDataframe = InsectSprays\nInsectLM = lm(sqrt(count) ~ spray, data=InsectsDataframe)\nplot(simulateResiduals(InsectLM))\n```\n\n::: {.cell-output-display}\n![](AnáliseInferencial_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nshapiro.test(residuals(InsectLM))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  residuals(InsectLM)\nW = 0.98721, p-value = 0.6814\n```\n\n\n:::\n\n```{.r .cell-code}\nMeans = emmeans(InsectLM, ~ spray)\ncld(Means)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95 \nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n\n\n### Two-way Anova\n\nA Anova fatorial de dois fatores (Two‑Way ANOVA) estende a ideia da análise de variância unidirecional para investigar simultaneamente o efeito de duas variáveis categóricas sobre uma variável resposta contínua, bem como a existência de interação entre elas. Enquanto na Anova simples comparamos apenas médias de um fator, na Anova fatorial avaliamos:\n\n-   **Efeito principal de cada fator** — se diferentes níveis levam, isoladamente, a diferenças significativas.\\\n\n-   **Interação entre fatores** — se o impacto de um fator depende do nível do outro.\n\nNo exemplo abaixo iremos utilizar um conjunto de dados para investigar o efeito e diferentes doses de fungicidas diferentes sob a severidade. Ajustando um modelo linear com interação entre os fatores dose e tratamento, podemos observar que os resíduos atendem as pressuposições, e observar a tabela de análise de variâncai indicando que houve diferença significativa entre os grupos da variável 'treat', 'dose' e da interação entre as duas.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nFungicideDataframe = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=2023059672#gid=2023059672\")\n\nFungicideDataframe |>\n  ggplot(aes(factor(dose), severity*100))+\n  geom_boxplot(outlier.color=NULL)+\n  geom_jitter(width=0.1)+\n  facet_wrap(~treat)\n```\n\n::: {.cell-output-display}\n![](AnáliseInferencial_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#\nMFungicide = lm(severity ~treat*dose, data=FungicideDataframe)\nhist(residuals(MFungicide))\n```\n\n::: {.cell-output-display}\n![](AnáliseInferencial_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(simulateResiduals(MFungicide))\n```\n\n::: {.cell-output-display}\n![](AnáliseInferencial_files/figure-html/unnamed-chunk-8-3.png){width=672}\n:::\n\n```{.r .cell-code}\nanova(MFungicide)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: severity\n           Df   Sum Sq  Mean Sq F value    Pr(>F)    \ntreat       1 0.113232 0.113232  30.358 4.754e-05 ***\ndose        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:dose  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals  16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualizing significance interaction\nggplot(FungicideDataframe, aes(x = dose, y = severity*100, \n                                group = treat, color = treat)) +\n  stat_summary(fun = mean, geom = \"line\") +           # linhas de tendência\n  stat_summary(fun = mean, geom = \"point\", shape = 16) + # pontos médios\n  stat_summary(fun.data = mean_se, geom = \"errorbar\", width = 0.1) + # barras de erro (SE)\n  scale_color_brewer(palette = \"Set1\", name = \"Tratamento\") +\n  labs(\n    x     = \"Dose\",\n    y     = \"Severidade (%)\",\n    title = \"Interação entre Dose e Tratamento na Severidade\",\n    caption = \"Médias com intervalo de erro padrão\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    legend.position = \"top\",\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(face = \"bold\", hjust = 0.5)\n  )\n```\n\n::: {.cell-output-display}\n![](AnáliseInferencial_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\nPara finalizar podemos identificar os grupos que apresentaram diferenças significativas, por nível de tratamento ou dose.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMediasFungicideByDose = emmeans(MFungicide, ~treat|dose)\ncld(MediasFungicideByDose, Letters = letters)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789  a    \n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500   b   \n\ndose = 2.0:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781  a    \n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080  a    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n\n```{.r .cell-code}\nMediasFungicideByTreat = emmeans(MFungicide, ~dose|treat)\ncld(MediasFungicideByTreat, Letters = letters)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  a    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   b   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  a    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  a    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n\n\n### Teste T\n\nOu método comum para identificar se há diferença significativa entre médias é o teste T de Student. No teste T um valor de T é obtido e comparado a um valor tabelo em função do número de graus de liberdade. Caso o T valor seja maior que o valor crítico tabelado, a hipótese nula é rejeita (H0: Não há diferença significativa), adotando a hipótese alternativa de que há diferença significativa (H1).\n\n#### Independente\n\nSua forma independente requer amostras que não exersem influência entre si, ou seja não há relação entre os valores. O valor de T é obtido através da razão entre a difereça das médias pelo erro padrão agrupado.\n\n$$\n\\begin{align*}t &= \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}} \\\\\\\\\\ \\\\\\bar{X}_1 &\\quad \\text{é a média da amostra do grupo 1} \\\\\\bar{X}_2 &\\quad \\text{é a média da amostra do grupo 2} \\\\s_1^2 &\\quad \\text{é a variância da amostra do grupo 1} \\\\s_2^2 &\\quad \\text{é a variância da amostra do grupo 2} \\\\n_1 &\\quad \\text{é o tamanho da amostra do grupo 1} \\\\n_2 &\\quad \\text{é o tamanho da amostra do grupo 2} \\\\t &\\quad \\text{é o valor do teste t calculado}\\end{align*}\n$$\n\nComo exemplo vamos utilizar um conjunto de dados com observaçõs de comprimento com e sem o uso de Mg2. Inicalmente vamos verificar a normalidade de homogenidade das variâncias, averiguando que os dados seguem a distribuição normal e os grupos possuem variância homogenea.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMgDataframe <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137\")\nMgDataframeWide <- MgDataframe |> \n  pivot_wider(names_from = trat, values_from = comp)\n\nshapiro.test(MgDataframeWide$control)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  MgDataframeWide$control\nW = 0.93886, p-value = 0.5404\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(MgDataframeWide$Mg2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  MgDataframeWide$Mg2\nW = 0.97269, p-value = 0.9146\n```\n\n\n:::\n\n```{.r .cell-code}\nvar.test(MgDataframeWide$control, MgDataframeWide$Mg2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tF test to compare two variances\n\ndata:  MgDataframeWide$control and MgDataframeWide$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n```\n\n\n:::\n:::\n\n\n\n\nEm seguida vamos performar o test t independent para verificar se houve diferença significativa entre os grupos. Constatando que há diferença entre os grupos.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTResult_base <- t.test(\n  MgDataframeWide$control,\n  MgDataframeWide$Mg2,\n  var.equal = TRUE\n)\ntidy(TResult_base)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic    p.value parameter conf.low conf.high\n     <dbl>     <dbl>     <dbl>     <dbl>      <dbl>     <dbl>    <dbl>     <dbl>\n1     5.16      15.7      10.5      8.15    1.86e-7        18     3.83      6.49\n# ℹ 2 more variables: method <chr>, alternative <chr>\n```\n\n\n:::\n:::\n\n\n\n\n#### Pareado\n\nAmostras pareadas envolvem observações relacionadas em pares, onde cada elemento de um grupo está diretamente vinculado a um elemento do outro grupo.\n\nSeu valor de T é obtido pela equação abaixo:\n\n\\\n$$\n\\begin{align*}t &= \\frac{\\bar{d}}{s_d / \\sqrt{n}}  \\\\\\bar{d} &\\quad \\text{é a média das diferenças entre os pares de observações} \\\\s_d &\\quad \\text{é o desvio padrão das diferenças} \\\\n &\\quad \\text{é o número de pares de observações} \\\\t &\\quad \\text{é o valor do teste t calculado}\\end{align*}\n$$\n\nPara ilustrar o teste T pareado vamos utilizar um conjunto de dados em que diferentes avaliadores realizaram classificações com e sem o auxílio de escala. É preciso somente verificar se a diferença entre as observações pareadas seguem a normalidade e o teste pode ser executado. Conforme podemos observar que houve diferença significativa\\\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nScaleDataframe <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1729131173#gid=1729131173\")\n\nUnaided <- ScaleDataframe |> filter(assessment == \"Unaided\") |> pull(acuracia)\nAided   <- ScaleDataframe |> filter(assessment == \"Aided1\")  |> pull(acuracia)\n\ndifferences <- Unaided - Aided\nshapiro.test(differences)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  differences\nW = 0.858, p-value = 0.07227\n```\n\n\n:::\n\n```{.r .cell-code}\nScaleTTest <- t.test(\n  Unaided,\n  Aided,\n  paired  = TRUE,\n  var.equal = FALSE\n)\ntidy(ScaleTTest)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 8\n  estimate statistic p.value parameter conf.low conf.high method     alternative\n     <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl> <chr>      <chr>      \n1   -0.235     -4.42 0.00167         9   -0.355    -0.115 Paired t-… two.sided  \n```\n\n\n:::\n:::\n",
    "supporting": [
      "AnáliseInferencial_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}