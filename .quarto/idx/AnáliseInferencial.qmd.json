{"title":"Análise paramétrica","markdown":{"yaml":{"title":"Análise paramétrica","warning":false},"headingText":"Análise inferencial","containsRefs":false,"markdown":"\n\n\nA estatística inferencial é o ramo da estatística responsável por permitir a inferência de conclusões sobre uma população com base na análise de uma amostra representativa. A inferência ocorre a partir do teste de hipoteses, que evidencia a diferença entre os fatores comparados. Amparado pelo valor de P, probabilidade da hipótese nula obter um resultado tão extremo quanto o observado. Além dos testes, a estatística inferencial inclui métodos de estimativa de parâmetros e intervalos de confiança, e fornece compreensão sobre sobre o efeito de preditores e gerar predições. Podemos classificar os teste entre paramétricos e não paramétricos baseados nas suposições sobre os dados que são requeridas para que sejam aplicados. Os paramétricos requerem que a distruição dos dados siga um padrão conhecido, enquanto os não paramétricos não requerem uma distribuição específica.\n\nPara aprendermos sobre estatítica inferencial paramétrica, vamos utilizar o conjunto de dados que contém o tamanho de colônias de fungos de diferentes espécies. Buscaremos identificar se há diferença entre as espécies, utilizando o teste T, Anova e teste de PosHoc\n\n```{R}\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(report)\nlibrary(rstatix)\nlibrary(gsheet)\nlibrary(emmeans)\nlibrary(multcompView)\nlibrary(multcomp)\nlibrary(agricolae)\nlibrary(DT)\nlibrary(DHARMa)\n\nMiceliaDataframe = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=959387827#gid=959387827\")\nMiceliaDataframe\n```\n\n### Análise utilizando Anova (analysis of variance)\n\nMétodo estatístico paramétrico que visa identificar se há diferença significativa entre três ou mais grupos independentes, por comparação da variância. Possibilitando distinguir se a variação (Soma do quadrado dos resíduos), é explicada por aleatoriedade (Soma do quadrado dos resíduos em relação a média dos grupos) ou por características distinta dos grupos (Soma do quadrado dos resíduos em relação a média total).\n\n**Soma do quadrado dos resíduos:**\n\nResíduos são a diferença entre o valor observado e uma média. Seja em relação a média total ou dentro de um grupo\n\n$$\ne_i \\;=\\; y_i \\;-\\; \\hat y_i\n$$\n\n$$\n\\begin{align*}e_i &\\quad \\text{é o resíduo da i-ésima observação (erro de predição)} \\\\y_i &\\quad \\text{é o valor observado da i-ésima observação} \\\\\\hat{y}_i &\\quad \\text{é o valor previsto pelo modelo para a i-ésima observação}\\end{align*}\n$$\n\n```{R}\nmean_global <- mean(MiceliaDataframe$tcm)\nMiceliaDataframe %>%\n  ggplot(aes(x = especie, y = tcm)) +\n  geom_boxplot(outlier.colour = NA) +\n  geom_jitter(aes(color = especie), width = 0.2) +\n  stat_summary(\n    aes(shape = \"Média por Espécie\"),\n    fun    = mean,\n    geom   = \"point\",\n    size   = 3,\n    color  = \"black\",\n    fill   = \"black\"\n  ) +\n  geom_hline(\n    aes(\n      yintercept = mean_global,\n      linetype   = \"Média Global\"\n    ),\n    color = \"black\",\n    size  = 0.7\n  ) +\n  scale_shape_manual(\n    name   = \"\",\n    values = c(\"Média por Espécie\" = 16)\n  ) +\n  scale_linetype_manual(\n    name   = \"\",\n    values = c(\"Média Global\" = \"solid\")\n  ) +\n  guides(\n    shape    = guide_legend(override.aes = list(linetype = 0)),\n    linetype = guide_legend(override.aes = list(shape    = NA))\n  )\n\n```\n\nElevando o resíduo ao quadrado almejamos a evidenciar grandes discrepâncias, a garantir que a soma total será uma mensuração de variabilidade absoluta e permite maior conveniência matemática. Uma vez que será uma função convexa conhecida dos parâmetros do modelo.\n\nPortanto podemos compreender a soma do quadrado dos resíduo como uma mensuração do quanto da variabilidade não é explicada pelo modelo.\n\n$$\nSQR_{\\mathrm{res}}\n\\;=\\;\n\\sum_{i=1}^n e_i^2\n\\;=\\;\n\\sum_{i=1}^n (y_i - \\hat y_i)^2\n$$\n\n$$\n\\begin{align*}SQR_{\\mathrm{res}} &\\quad \\text{é a Soma dos Quadrados dos Resíduos} \\\\\\sum_{i=1}^n &\\quad \\text{indica a soma para todas as observações de i = 1 até n} \\\\e_i &\\quad \\text{é o resíduo da i-ésima observação (} e_i = y_i - \\hat{y}_i \\text{)} \\\\y_i &\\quad \\text{é o valor observado da i-ésima observação} \\\\\\hat{y}_i &\\quad \\text{é o valor previsto pelo modelo para a i-ésima observação} \\\\n &\\quad \\text{é o número total de observações}\\end{align*}\n$$\n\nObtemos o valor de F através da razão entre a diferença entre as somas dos quadrados dos resíduos (SQR) divido pela diferença entre número de parâmetros dos modelos (P), e a SQR(grupo) dividido pela diferença entre o número de amostras pelo número de parâmetros do modelos da média total. F demostra a relação entre variabilidade entre os grupos e a aleatoriedade, dado a varibilidade interna de cada grupo. Portanto quando a variância explicada é maior que a variância não explicada F \\> 1 ao menos um possui diferença significativa.\n\n$$\nF = \\frac{\\text{Variância explicada}}{\\text{Variância não explicada}} = \n\\frac{\n  \\displaystyle \\frac{SS(\\text{mean}) - SS(\\text{fit})}{P(\\text{fit}) - P(\\text{mean})}\n}{\n  \\displaystyle \\frac{SS(\\text{fit})}{n - P(\\text{fit})}\n}\n$$O P-valor indicada a probabilidade de observar essa variabilidade ou outra ainda mais extrema, no caso de hipótese nula (H0: sem diferença entre grupos). Portanto ao obtermos um pequeno P-valor temos uma probabilidade baixa o suficiente para recursarmos H0 e adotarmos a hipótese alternativa (H1: há ao menos um grupo com diferença significativa), interpretando o como o fenômeno que ocorreu é improvável de ocorrer sob a condições de H0. O p-valor é obtido pela área abaixo da curva de distribuição de F, na qual temos a densidade de probabilidade em função dos valores de F, integrando os valores mais extremos que o F encontrado.\n\n![](P-valor.gif){fig-alt=\"Ilustração animada do p‑valor\" fig-align=\"center\"}\n\n#### Checagem das premissas\n\nAntes da aplicação de testes inferenciais, é essencial verificar se os dados atendem às suposições exigidas pelos modelos estatísticos. No caso da Anova as principais suposições são:\n\n-   **Normalidade dos resíduos**, avaliada por meio de testes como o *Shapiro-Wilk* e por inspeção visual de histogramas;\n\n-   **Homogeneidade de variâncias** entre os grupos, verificada por testes como *F de Fisher* (para duas amostras) ou *Bartlett* (para múltiplos grupos);\n\n-   **Independência das observações**, que garante que os valores analisados não estejam correlacionados entre si.\n\nA validação dessas suposições assegura a confiabilidade dos resultados e evita conclusões equivocadas.\n\n#### Normalidade\n\nComo passos iniciais da análise, vamos ajustar um modelo de análise da variância com a função aov(). Com o objetivo de avaliar se há diferença significativa entre o valor da variável 'tcm' de cada 'espécie'.\\\nPara validar o uso do modelo, vamos verificar se os resíduos (diferenças entre as observações e os preditos) seguem a distribuição normal. A verificação pode ser feita de maneira visual, através do histograma dos resíduos. Ou de forma mais analítica como o teste de shapiro-wilk, que considera como hipotese nula que o comportamento difere da normalidade. Sendo assim necessário obter um P-valor maior do que Alfa (0.05) para confirmar a normalidade.\n\n```{R}\n# Teste de normalidade dos resíduos do modelo\nAnovaModel <- aov(tcm ~ especie, data = MiceliaDataframe)\nhist(residuals(AnovaModel), main = \"Histograma dos Resíduos\",\n     xlab='Resíduos', ylab = 'Frequência')\nshapiro.test(residuals(AnovaModel))\n```\n\n#### Homocedasticidade\n\nOutra suposição necessária para validar a aplicação do teste de Anova, é a homogenidade das variâncias. Uma teste comum que permite essa averiguação é o teste de bartlett, em que a hipótese nula assume que as variâncias dos tratamentos são iguais. Caso p-valor seja maior que alfa (0.05), confirmamos a homocedasticidade.\n\n```{R}\n# Teste de homogeneidade de variância\nbartlett.test(tcm ~ especie, data = MiceliaDataframe)\n```\n\n#### Tabela Anova\n\nA tabela de análise Anova, permite a avaliação dos resultados e performance do teste. Através dela podemos observar o grau de liberdade, soma e média dos quadrados dos resíduos, valor de F e P.\n\n```{R}\nsummary(AnovaModel)\n```\n\n### Post-hoc\n\nApós análise de variância, e a detecção de que há diferenças significativas, seguimos investigando para identificar quas grupos são diferentes entre si. Para isso sçao comumente aplicados testes de Post-hoc, realizam a comparação todas as combinações possíveis entre os grupos enquanto se controla a chance de ocorrer falsos positivos ao ajustar o nível de significância.\n\nComo exemplo vamos utilizar EMMs (média marginal estimada) que utiliza médias ajustadas, corrigindo desequilíbrios no número de observações e efeito de covariáveis. \\*\n\nPara facilitar a visualização, vamos organizar os grupo identificando-os como letras (a,b,c)\n\n```{R}\n# Comparação de médias com EMMeans\nem <- emmeans(AnovaModel, ~ especie)\ncld(em, Letters = letters)\n```\n\n### Tranformação dos dados\n\nCaso o conjunto de valores não siga a normalidade, uma alternativa é transformar os dados. Ajustando sua distribuição a normalidade. Utilizando o mesmo conjunto de dados iremos utilizar a raiz quadrada como forma de ajuste. A raiz quadrada permite a \"compressão\" dos valores de maneira proporcional a grandeza do valor, ajustando a simetria da distribuição. A analisarmos a distribuição dos resíduos novamente, podemos observar que foi averguado que os resíduos agora seguem a normalidade e homocedasticidade.\n\n```{R}\nInsectsDataframe = InsectSprays\nInsectLM = lm(sqrt(count) ~ spray, data=InsectsDataframe)\nplot(simulateResiduals(InsectLM))\nshapiro.test(residuals(InsectLM))\n\nMeans = emmeans(InsectLM, ~ spray)\ncld(Means)\n```\n\n### Two-way Anova\n\nA Anova fatorial de dois fatores (Two‑Way ANOVA) estende a ideia da análise de variância unidirecional para investigar simultaneamente o efeito de duas variáveis categóricas sobre uma variável resposta contínua, bem como a existência de interação entre elas. Enquanto na Anova simples comparamos apenas médias de um fator, na Anova fatorial avaliamos:\n\n-   **Efeito principal de cada fator** — se diferentes níveis levam, isoladamente, a diferenças significativas.\\\n\n-   **Interação entre fatores** — se o impacto de um fator depende do nível do outro.\n\nNo exemplo abaixo iremos utilizar um conjunto de dados para investigar o efeito e diferentes doses de fungicidas diferentes sob a severidade. Ajustando um modelo linear com interação entre os fatores dose e tratamento, podemos observar que os resíduos atendem as pressuposições, e observar a tabela de análise de variâncai indicando que houve diferença significativa entre os grupos da variável 'treat', 'dose' e da interação entre as duas.\n\n```{R}\nFungicideDataframe = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=2023059672#gid=2023059672\")\n\nFungicideDataframe |>\n  ggplot(aes(factor(dose), severity*100))+\n  geom_boxplot(outlier.color=NULL)+\n  geom_jitter(width=0.1)+\n  facet_wrap(~treat)\n\n#\nMFungicide = lm(severity ~treat*dose, data=FungicideDataframe)\nhist(residuals(MFungicide))\nplot(simulateResiduals(MFungicide))\nanova(MFungicide)\n```\n\n```{R}\n# Visualizing significance interaction\nggplot(FungicideDataframe, aes(x = dose, y = severity*100, \n                                group = treat, color = treat)) +\n  stat_summary(fun = mean, geom = \"line\") +           # linhas de tendência\n  stat_summary(fun = mean, geom = \"point\", shape = 16) + # pontos médios\n  stat_summary(fun.data = mean_se, geom = \"errorbar\", width = 0.1) + # barras de erro (SE)\n  scale_color_brewer(palette = \"Set1\", name = \"Tratamento\") +\n  labs(\n    x     = \"Dose\",\n    y     = \"Severidade (%)\",\n    title = \"Interação entre Dose e Tratamento na Severidade\",\n    caption = \"Médias com intervalo de erro padrão\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    legend.position = \"top\",\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(face = \"bold\", hjust = 0.5)\n  )\n```\n\nPara finalizar podemos identificar os grupos que apresentaram diferenças significativas, por nível de tratamento ou dose.\n\n```{R}\nMediasFungicideByDose = emmeans(MFungicide, ~treat|dose)\ncld(MediasFungicideByDose, Letters = letters)\n\nMediasFungicideByTreat = emmeans(MFungicide, ~dose|treat)\ncld(MediasFungicideByTreat, Letters = letters)\n```\n\n### Teste T\n\nOu método comum para identificar se há diferença significativa entre médias é o teste T de Student. No teste T um valor de T é obtido e comparado a um valor tabelo em função do número de graus de liberdade. Caso o T valor seja maior que o valor crítico tabelado, a hipótese nula é rejeita (H0: Não há diferença significativa), adotando a hipótese alternativa de que há diferença significativa (H1).\n\n#### Independente\n\nSua forma independente requer amostras que não exersem influência entre si, ou seja não há relação entre os valores. O valor de T é obtido através da razão entre a difereça das médias pelo erro padrão agrupado.\n\n$$\n\\begin{align*}t &= \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}} \\\\\\\\\\ \\\\\\bar{X}_1 &\\quad \\text{é a média da amostra do grupo 1} \\\\\\bar{X}_2 &\\quad \\text{é a média da amostra do grupo 2} \\\\s_1^2 &\\quad \\text{é a variância da amostra do grupo 1} \\\\s_2^2 &\\quad \\text{é a variância da amostra do grupo 2} \\\\n_1 &\\quad \\text{é o tamanho da amostra do grupo 1} \\\\n_2 &\\quad \\text{é o tamanho da amostra do grupo 2} \\\\t &\\quad \\text{é o valor do teste t calculado}\\end{align*}\n$$\n\nComo exemplo vamos utilizar um conjunto de dados com observaçõs de comprimento com e sem o uso de Mg2. Inicalmente vamos verificar a normalidade de homogenidade das variâncias, averiguando que os dados seguem a distribuição normal e os grupos possuem variância homogenea.\n\n```{R}\nMgDataframe <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137\")\nMgDataframeWide <- MgDataframe |> \n  pivot_wider(names_from = trat, values_from = comp)\n\nshapiro.test(MgDataframeWide$control)\nshapiro.test(MgDataframeWide$Mg2)\n\nvar.test(MgDataframeWide$control, MgDataframeWide$Mg2)\n```\n\nEm seguida vamos performar o test t independent para verificar se houve diferença significativa entre os grupos. Constatando que há diferença entre os grupos.\n\n```{R}\nTResult_base <- t.test(\n  MgDataframeWide$control,\n  MgDataframeWide$Mg2,\n  var.equal = TRUE\n)\ntidy(TResult_base)\n```\n\n#### Pareado\n\nAmostras pareadas envolvem observações relacionadas em pares, onde cada elemento de um grupo está diretamente vinculado a um elemento do outro grupo.\n\nSeu valor de T é obtido pela equação abaixo:\n\n\\\n$$\n\\begin{align*}t &= \\frac{\\bar{d}}{s_d / \\sqrt{n}}  \\\\\\bar{d} &\\quad \\text{é a média das diferenças entre os pares de observações} \\\\s_d &\\quad \\text{é o desvio padrão das diferenças} \\\\n &\\quad \\text{é o número de pares de observações} \\\\t &\\quad \\text{é o valor do teste t calculado}\\end{align*}\n$$\n\nPara ilustrar o teste T pareado vamos utilizar um conjunto de dados em que diferentes avaliadores realizaram classificações com e sem o auxílio de escala. É preciso somente verificar se a diferença entre as observações pareadas seguem a normalidade e o teste pode ser executado. Conforme podemos observar que houve diferença significativa\\\n\n```{R}\nScaleDataframe <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1729131173#gid=1729131173\")\n\nUnaided <- ScaleDataframe |> filter(assessment == \"Unaided\") |> pull(acuracia)\nAided   <- ScaleDataframe |> filter(assessment == \"Aided1\")  |> pull(acuracia)\n\ndifferences <- Unaided - Aided\nshapiro.test(differences)\n\nScaleTTest <- t.test(\n  Unaided,\n  Aided,\n  paired  = TRUE,\n  var.equal = FALSE\n)\ntidy(ScaleTTest)\n```\n","srcMarkdownNoYaml":"\n\n## Análise inferencial\n\nA estatística inferencial é o ramo da estatística responsável por permitir a inferência de conclusões sobre uma população com base na análise de uma amostra representativa. A inferência ocorre a partir do teste de hipoteses, que evidencia a diferença entre os fatores comparados. Amparado pelo valor de P, probabilidade da hipótese nula obter um resultado tão extremo quanto o observado. Além dos testes, a estatística inferencial inclui métodos de estimativa de parâmetros e intervalos de confiança, e fornece compreensão sobre sobre o efeito de preditores e gerar predições. Podemos classificar os teste entre paramétricos e não paramétricos baseados nas suposições sobre os dados que são requeridas para que sejam aplicados. Os paramétricos requerem que a distruição dos dados siga um padrão conhecido, enquanto os não paramétricos não requerem uma distribuição específica.\n\nPara aprendermos sobre estatítica inferencial paramétrica, vamos utilizar o conjunto de dados que contém o tamanho de colônias de fungos de diferentes espécies. Buscaremos identificar se há diferença entre as espécies, utilizando o teste T, Anova e teste de PosHoc\n\n```{R}\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(report)\nlibrary(rstatix)\nlibrary(gsheet)\nlibrary(emmeans)\nlibrary(multcompView)\nlibrary(multcomp)\nlibrary(agricolae)\nlibrary(DT)\nlibrary(DHARMa)\n\nMiceliaDataframe = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=959387827#gid=959387827\")\nMiceliaDataframe\n```\n\n### Análise utilizando Anova (analysis of variance)\n\nMétodo estatístico paramétrico que visa identificar se há diferença significativa entre três ou mais grupos independentes, por comparação da variância. Possibilitando distinguir se a variação (Soma do quadrado dos resíduos), é explicada por aleatoriedade (Soma do quadrado dos resíduos em relação a média dos grupos) ou por características distinta dos grupos (Soma do quadrado dos resíduos em relação a média total).\n\n**Soma do quadrado dos resíduos:**\n\nResíduos são a diferença entre o valor observado e uma média. Seja em relação a média total ou dentro de um grupo\n\n$$\ne_i \\;=\\; y_i \\;-\\; \\hat y_i\n$$\n\n$$\n\\begin{align*}e_i &\\quad \\text{é o resíduo da i-ésima observação (erro de predição)} \\\\y_i &\\quad \\text{é o valor observado da i-ésima observação} \\\\\\hat{y}_i &\\quad \\text{é o valor previsto pelo modelo para a i-ésima observação}\\end{align*}\n$$\n\n```{R}\nmean_global <- mean(MiceliaDataframe$tcm)\nMiceliaDataframe %>%\n  ggplot(aes(x = especie, y = tcm)) +\n  geom_boxplot(outlier.colour = NA) +\n  geom_jitter(aes(color = especie), width = 0.2) +\n  stat_summary(\n    aes(shape = \"Média por Espécie\"),\n    fun    = mean,\n    geom   = \"point\",\n    size   = 3,\n    color  = \"black\",\n    fill   = \"black\"\n  ) +\n  geom_hline(\n    aes(\n      yintercept = mean_global,\n      linetype   = \"Média Global\"\n    ),\n    color = \"black\",\n    size  = 0.7\n  ) +\n  scale_shape_manual(\n    name   = \"\",\n    values = c(\"Média por Espécie\" = 16)\n  ) +\n  scale_linetype_manual(\n    name   = \"\",\n    values = c(\"Média Global\" = \"solid\")\n  ) +\n  guides(\n    shape    = guide_legend(override.aes = list(linetype = 0)),\n    linetype = guide_legend(override.aes = list(shape    = NA))\n  )\n\n```\n\nElevando o resíduo ao quadrado almejamos a evidenciar grandes discrepâncias, a garantir que a soma total será uma mensuração de variabilidade absoluta e permite maior conveniência matemática. Uma vez que será uma função convexa conhecida dos parâmetros do modelo.\n\nPortanto podemos compreender a soma do quadrado dos resíduo como uma mensuração do quanto da variabilidade não é explicada pelo modelo.\n\n$$\nSQR_{\\mathrm{res}}\n\\;=\\;\n\\sum_{i=1}^n e_i^2\n\\;=\\;\n\\sum_{i=1}^n (y_i - \\hat y_i)^2\n$$\n\n$$\n\\begin{align*}SQR_{\\mathrm{res}} &\\quad \\text{é a Soma dos Quadrados dos Resíduos} \\\\\\sum_{i=1}^n &\\quad \\text{indica a soma para todas as observações de i = 1 até n} \\\\e_i &\\quad \\text{é o resíduo da i-ésima observação (} e_i = y_i - \\hat{y}_i \\text{)} \\\\y_i &\\quad \\text{é o valor observado da i-ésima observação} \\\\\\hat{y}_i &\\quad \\text{é o valor previsto pelo modelo para a i-ésima observação} \\\\n &\\quad \\text{é o número total de observações}\\end{align*}\n$$\n\nObtemos o valor de F através da razão entre a diferença entre as somas dos quadrados dos resíduos (SQR) divido pela diferença entre número de parâmetros dos modelos (P), e a SQR(grupo) dividido pela diferença entre o número de amostras pelo número de parâmetros do modelos da média total. F demostra a relação entre variabilidade entre os grupos e a aleatoriedade, dado a varibilidade interna de cada grupo. Portanto quando a variância explicada é maior que a variância não explicada F \\> 1 ao menos um possui diferença significativa.\n\n$$\nF = \\frac{\\text{Variância explicada}}{\\text{Variância não explicada}} = \n\\frac{\n  \\displaystyle \\frac{SS(\\text{mean}) - SS(\\text{fit})}{P(\\text{fit}) - P(\\text{mean})}\n}{\n  \\displaystyle \\frac{SS(\\text{fit})}{n - P(\\text{fit})}\n}\n$$O P-valor indicada a probabilidade de observar essa variabilidade ou outra ainda mais extrema, no caso de hipótese nula (H0: sem diferença entre grupos). Portanto ao obtermos um pequeno P-valor temos uma probabilidade baixa o suficiente para recursarmos H0 e adotarmos a hipótese alternativa (H1: há ao menos um grupo com diferença significativa), interpretando o como o fenômeno que ocorreu é improvável de ocorrer sob a condições de H0. O p-valor é obtido pela área abaixo da curva de distribuição de F, na qual temos a densidade de probabilidade em função dos valores de F, integrando os valores mais extremos que o F encontrado.\n\n![](P-valor.gif){fig-alt=\"Ilustração animada do p‑valor\" fig-align=\"center\"}\n\n#### Checagem das premissas\n\nAntes da aplicação de testes inferenciais, é essencial verificar se os dados atendem às suposições exigidas pelos modelos estatísticos. No caso da Anova as principais suposições são:\n\n-   **Normalidade dos resíduos**, avaliada por meio de testes como o *Shapiro-Wilk* e por inspeção visual de histogramas;\n\n-   **Homogeneidade de variâncias** entre os grupos, verificada por testes como *F de Fisher* (para duas amostras) ou *Bartlett* (para múltiplos grupos);\n\n-   **Independência das observações**, que garante que os valores analisados não estejam correlacionados entre si.\n\nA validação dessas suposições assegura a confiabilidade dos resultados e evita conclusões equivocadas.\n\n#### Normalidade\n\nComo passos iniciais da análise, vamos ajustar um modelo de análise da variância com a função aov(). Com o objetivo de avaliar se há diferença significativa entre o valor da variável 'tcm' de cada 'espécie'.\\\nPara validar o uso do modelo, vamos verificar se os resíduos (diferenças entre as observações e os preditos) seguem a distribuição normal. A verificação pode ser feita de maneira visual, através do histograma dos resíduos. Ou de forma mais analítica como o teste de shapiro-wilk, que considera como hipotese nula que o comportamento difere da normalidade. Sendo assim necessário obter um P-valor maior do que Alfa (0.05) para confirmar a normalidade.\n\n```{R}\n# Teste de normalidade dos resíduos do modelo\nAnovaModel <- aov(tcm ~ especie, data = MiceliaDataframe)\nhist(residuals(AnovaModel), main = \"Histograma dos Resíduos\",\n     xlab='Resíduos', ylab = 'Frequência')\nshapiro.test(residuals(AnovaModel))\n```\n\n#### Homocedasticidade\n\nOutra suposição necessária para validar a aplicação do teste de Anova, é a homogenidade das variâncias. Uma teste comum que permite essa averiguação é o teste de bartlett, em que a hipótese nula assume que as variâncias dos tratamentos são iguais. Caso p-valor seja maior que alfa (0.05), confirmamos a homocedasticidade.\n\n```{R}\n# Teste de homogeneidade de variância\nbartlett.test(tcm ~ especie, data = MiceliaDataframe)\n```\n\n#### Tabela Anova\n\nA tabela de análise Anova, permite a avaliação dos resultados e performance do teste. Através dela podemos observar o grau de liberdade, soma e média dos quadrados dos resíduos, valor de F e P.\n\n```{R}\nsummary(AnovaModel)\n```\n\n### Post-hoc\n\nApós análise de variância, e a detecção de que há diferenças significativas, seguimos investigando para identificar quas grupos são diferentes entre si. Para isso sçao comumente aplicados testes de Post-hoc, realizam a comparação todas as combinações possíveis entre os grupos enquanto se controla a chance de ocorrer falsos positivos ao ajustar o nível de significância.\n\nComo exemplo vamos utilizar EMMs (média marginal estimada) que utiliza médias ajustadas, corrigindo desequilíbrios no número de observações e efeito de covariáveis. \\*\n\nPara facilitar a visualização, vamos organizar os grupo identificando-os como letras (a,b,c)\n\n```{R}\n# Comparação de médias com EMMeans\nem <- emmeans(AnovaModel, ~ especie)\ncld(em, Letters = letters)\n```\n\n### Tranformação dos dados\n\nCaso o conjunto de valores não siga a normalidade, uma alternativa é transformar os dados. Ajustando sua distribuição a normalidade. Utilizando o mesmo conjunto de dados iremos utilizar a raiz quadrada como forma de ajuste. A raiz quadrada permite a \"compressão\" dos valores de maneira proporcional a grandeza do valor, ajustando a simetria da distribuição. A analisarmos a distribuição dos resíduos novamente, podemos observar que foi averguado que os resíduos agora seguem a normalidade e homocedasticidade.\n\n```{R}\nInsectsDataframe = InsectSprays\nInsectLM = lm(sqrt(count) ~ spray, data=InsectsDataframe)\nplot(simulateResiduals(InsectLM))\nshapiro.test(residuals(InsectLM))\n\nMeans = emmeans(InsectLM, ~ spray)\ncld(Means)\n```\n\n### Two-way Anova\n\nA Anova fatorial de dois fatores (Two‑Way ANOVA) estende a ideia da análise de variância unidirecional para investigar simultaneamente o efeito de duas variáveis categóricas sobre uma variável resposta contínua, bem como a existência de interação entre elas. Enquanto na Anova simples comparamos apenas médias de um fator, na Anova fatorial avaliamos:\n\n-   **Efeito principal de cada fator** — se diferentes níveis levam, isoladamente, a diferenças significativas.\\\n\n-   **Interação entre fatores** — se o impacto de um fator depende do nível do outro.\n\nNo exemplo abaixo iremos utilizar um conjunto de dados para investigar o efeito e diferentes doses de fungicidas diferentes sob a severidade. Ajustando um modelo linear com interação entre os fatores dose e tratamento, podemos observar que os resíduos atendem as pressuposições, e observar a tabela de análise de variâncai indicando que houve diferença significativa entre os grupos da variável 'treat', 'dose' e da interação entre as duas.\n\n```{R}\nFungicideDataframe = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=2023059672#gid=2023059672\")\n\nFungicideDataframe |>\n  ggplot(aes(factor(dose), severity*100))+\n  geom_boxplot(outlier.color=NULL)+\n  geom_jitter(width=0.1)+\n  facet_wrap(~treat)\n\n#\nMFungicide = lm(severity ~treat*dose, data=FungicideDataframe)\nhist(residuals(MFungicide))\nplot(simulateResiduals(MFungicide))\nanova(MFungicide)\n```\n\n```{R}\n# Visualizing significance interaction\nggplot(FungicideDataframe, aes(x = dose, y = severity*100, \n                                group = treat, color = treat)) +\n  stat_summary(fun = mean, geom = \"line\") +           # linhas de tendência\n  stat_summary(fun = mean, geom = \"point\", shape = 16) + # pontos médios\n  stat_summary(fun.data = mean_se, geom = \"errorbar\", width = 0.1) + # barras de erro (SE)\n  scale_color_brewer(palette = \"Set1\", name = \"Tratamento\") +\n  labs(\n    x     = \"Dose\",\n    y     = \"Severidade (%)\",\n    title = \"Interação entre Dose e Tratamento na Severidade\",\n    caption = \"Médias com intervalo de erro padrão\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    legend.position = \"top\",\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(face = \"bold\", hjust = 0.5)\n  )\n```\n\nPara finalizar podemos identificar os grupos que apresentaram diferenças significativas, por nível de tratamento ou dose.\n\n```{R}\nMediasFungicideByDose = emmeans(MFungicide, ~treat|dose)\ncld(MediasFungicideByDose, Letters = letters)\n\nMediasFungicideByTreat = emmeans(MFungicide, ~dose|treat)\ncld(MediasFungicideByTreat, Letters = letters)\n```\n\n### Teste T\n\nOu método comum para identificar se há diferença significativa entre médias é o teste T de Student. No teste T um valor de T é obtido e comparado a um valor tabelo em função do número de graus de liberdade. Caso o T valor seja maior que o valor crítico tabelado, a hipótese nula é rejeita (H0: Não há diferença significativa), adotando a hipótese alternativa de que há diferença significativa (H1).\n\n#### Independente\n\nSua forma independente requer amostras que não exersem influência entre si, ou seja não há relação entre os valores. O valor de T é obtido através da razão entre a difereça das médias pelo erro padrão agrupado.\n\n$$\n\\begin{align*}t &= \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}} \\\\\\\\\\ \\\\\\bar{X}_1 &\\quad \\text{é a média da amostra do grupo 1} \\\\\\bar{X}_2 &\\quad \\text{é a média da amostra do grupo 2} \\\\s_1^2 &\\quad \\text{é a variância da amostra do grupo 1} \\\\s_2^2 &\\quad \\text{é a variância da amostra do grupo 2} \\\\n_1 &\\quad \\text{é o tamanho da amostra do grupo 1} \\\\n_2 &\\quad \\text{é o tamanho da amostra do grupo 2} \\\\t &\\quad \\text{é o valor do teste t calculado}\\end{align*}\n$$\n\nComo exemplo vamos utilizar um conjunto de dados com observaçõs de comprimento com e sem o uso de Mg2. Inicalmente vamos verificar a normalidade de homogenidade das variâncias, averiguando que os dados seguem a distribuição normal e os grupos possuem variância homogenea.\n\n```{R}\nMgDataframe <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137\")\nMgDataframeWide <- MgDataframe |> \n  pivot_wider(names_from = trat, values_from = comp)\n\nshapiro.test(MgDataframeWide$control)\nshapiro.test(MgDataframeWide$Mg2)\n\nvar.test(MgDataframeWide$control, MgDataframeWide$Mg2)\n```\n\nEm seguida vamos performar o test t independent para verificar se houve diferença significativa entre os grupos. Constatando que há diferença entre os grupos.\n\n```{R}\nTResult_base <- t.test(\n  MgDataframeWide$control,\n  MgDataframeWide$Mg2,\n  var.equal = TRUE\n)\ntidy(TResult_base)\n```\n\n#### Pareado\n\nAmostras pareadas envolvem observações relacionadas em pares, onde cada elemento de um grupo está diretamente vinculado a um elemento do outro grupo.\n\nSeu valor de T é obtido pela equação abaixo:\n\n\\\n$$\n\\begin{align*}t &= \\frac{\\bar{d}}{s_d / \\sqrt{n}}  \\\\\\bar{d} &\\quad \\text{é a média das diferenças entre os pares de observações} \\\\s_d &\\quad \\text{é o desvio padrão das diferenças} \\\\n &\\quad \\text{é o número de pares de observações} \\\\t &\\quad \\text{é o valor do teste t calculado}\\end{align*}\n$$\n\nPara ilustrar o teste T pareado vamos utilizar um conjunto de dados em que diferentes avaliadores realizaram classificações com e sem o auxílio de escala. É preciso somente verificar se a diferença entre as observações pareadas seguem a normalidade e o teste pode ser executado. Conforme podemos observar que houve diferença significativa\\\n\n```{R}\nScaleDataframe <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1729131173#gid=1729131173\")\n\nUnaided <- ScaleDataframe |> filter(assessment == \"Unaided\") |> pull(acuracia)\nAided   <- ScaleDataframe |> filter(assessment == \"Aided1\")  |> pull(acuracia)\n\ndifferences <- Unaided - Aided\nshapiro.test(differences)\n\nScaleTTest <- t.test(\n  Unaided,\n  Aided,\n  paired  = TRUE,\n  var.equal = FALSE\n)\ntidy(ScaleTTest)\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"AnáliseInferencial.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","editor":"visual","theme":"cosmo","title":"Análise paramétrica"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}